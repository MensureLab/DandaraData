{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MensureLab/DandaraData/blob/main/DandaraData_Rev3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97OL5T_eQmno",
        "outputId": "ed6737ca-dd45-4fbe-b47a-f8a84657161a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (3.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE7Htl6jVAOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eba4b29-6e5e-48bc-9e75-f0cd9ed3d200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "=== PRIMEIRA RODADA: COMUNIDADES ESPECÍFICAS ===\n",
            "\n",
            "Comunidade Ilhotinha, do município Capivari De Baixo (SC), da região SUL,\n",
            "é mencionada no artigo de ID 3 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Córrego Do Rocha, do município Chapada Do Norte (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 5 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Lage Dos Negros, do município Campo Formoso (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 7 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Caraíbas, do município Pedras De Maria Da Cruz (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 8 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Caraíbas, do município Cônego Marinho (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 8 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Imbiral Cabeça Branca, do município Pedro Do Rosário (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 16 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Algodão, do município Pelotas (RS), da região SUL,\n",
            "é mencionada no artigo de ID 20 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Cumbe, do município Aracati (CE), da região NORDESTE,\n",
            "é mencionada no artigo de ID 21 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Baixa Da Linha, do município Cruz Das Almas (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 25 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Invernada Paiol De Telha, do município Pinhão (PR), Guarapuava (PR), e/ou Reserva Do Iguaçu (PR), da região SUL,\n",
            "é mencionada no artigo de ID 27 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Mata Cavalo, do município Nossa Senhora Do Livramento (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 30 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Jacarequara, do município Santa Luzia Do Pará (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 34 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Jacarequara, do município Santa Isabel Do Pará (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 34 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Tipitinga, do município Santa Luzia Do Pará (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 34 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Morada Da Paz, do município Triunfo (RS), da região SUL,\n",
            "é mencionada no artigo de ID 47 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Amazonas.\n",
            "\n",
            "Comunidade Morro De São João, do município Santa Rosa Do Tocantins (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 54 da tabela,\n",
            "estudada pela instituição Instituto Federal Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Comunidade Cafundá Astrogilda, do município Rio De Janeiro (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 61 da tabela,\n",
            "estudada pela instituição Secretaria Estadual De Educação Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Tiririca, do município Carnaubeira Da Penha (PE), da região NORDESTE,\n",
            "é mencionada no artigo de ID 78 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Barro Vermelho, do município Paulistana (PI), da região NORDESTE,\n",
            "é mencionada no artigo de ID 79 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Piauí Universidade De Iowa.\n",
            "\n",
            "Comunidade Contente, do município Paulistana (PI), da região NORDESTE,\n",
            "é mencionada no artigo de ID 79 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Piauí Universidade De Iowa.\n",
            "\n",
            "Comunidade Serra Das Viúvas, do município Água Branca (AL), da região NORDESTE,\n",
            "é mencionada no artigo de ID 83 da tabela,\n",
            "estudada pela instituição Universidade Federal De Alagoas Escola Estadual De Xingó Ii.\n",
            "\n",
            "Comunidade Pinguela, do município Amélia Rodrigues (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 85 da tabela,\n",
            "estudada pela instituição Universidade Federal De São Carlos.\n",
            "\n",
            "Comunidade Monte Alegre, do município São Luís Gonzaga Do Maranhão (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 88 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Embrapa Amazônia Oriental Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Monte Alegre, do município Itapecuru-Mirim (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 88 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Embrapa Amazônia Oriental Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Monte Alegre, do município Guimarães (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 88 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Embrapa Amazônia Oriental Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Monte Alegre, do município Bequimão (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 88 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Embrapa Amazônia Oriental Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Caldeirão, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 96 da tabela,\n",
            "estudada pela instituição Universidade Do Estado Do Pará Universidade Do Estado Do Pará Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Córrego Do Rocha, do município Chapada Do Norte (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 106 da tabela,\n",
            "estudada pela instituição Fundação Oswaldo Cruz Centro Federal De Educação Tecnológica De Minas Gerais.\n",
            "\n",
            "Comunidade Colônia Do Paiol, do município Bias Fortes (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 115 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Campinas.\n",
            "\n",
            "Comunidade Frechal, do município Mirinzal (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 120 da tabela,\n",
            "estudada pela instituição Universidade Estadual Do Maranhão Universidade Federal Do Maranhão.\n",
            "\n",
            "Nome ambíguo Mocambo, do município Ourém (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 125 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Museu Paraense Emílio Goeldi.\n",
            "\n",
            "Comunidade Caiana Dos Crioulos, do município Alagoa Grande (PB), da região NORDESTE,\n",
            "é mencionada no artigo de ID 129 da tabela,\n",
            "estudada pela instituição Universidade Estadual Da Paraíba.\n",
            "\n",
            "Comunidade Pinguela, do município Amélia Rodrigues (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 152 da tabela,\n",
            "estudada pela instituição Universidade Federal De São Carlos.\n",
            "\n",
            "Comunidade Abacatal-Aurá, do município Ananindeua (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 157 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio De Janeiro Universidade Federal Do Pará Universidade Do Estado Do Pará.\n",
            "\n",
            "Comunidade Cajá Dos Negros, do município Batalha (AL), da região NORDESTE,\n",
            "é mencionada no artigo de ID 160 da tabela,\n",
            "estudada pela instituição Universidade Federal De Alagoas Universidade Federal Do Rio Grande Do Norte Universidade Federal De Mato Grosso.\n",
            "\n",
            "Comunidade Caveira, do município Cabo Frio (RJ), e/ou São Pedro Da Aldeia (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 162 da tabela,\n",
            "estudada pela instituição Universidade Federal Fluminense Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Morada Da Paz, do município Triunfo (RS), da região SUL,\n",
            "é mencionada no artigo de ID 166 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Amazonas.\n",
            "\n",
            "Comunidade Alagoinhas, do município Gentio Do Ouro (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 168 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Buracão, do município Mineiros (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 171 da tabela,\n",
            "estudada pela instituição Universidade Federal De Goiás Instituto Federal De Educação Ciência E Tecnologia De Goiás.\n",
            "\n",
            "Comunidade Invernada Dos Negros, do município Abdon Batista (SC), e/ou Campos Novos (SC), da região SUL,\n",
            "é mencionada no artigo de ID 174 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Fronteira Sul Prefeitura Municipal De Chapecó.\n",
            "\n",
            "Comunidade Caiana Dos Crioulos, do município Alagoa Grande (PB), da região NORDESTE,\n",
            "é mencionada no artigo de ID 175 da tabela,\n",
            "estudada pela instituição Universidade Estadual Da Paraíba.\n",
            "\n",
            "Comunidade Baú, do município Serro (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 180 da tabela,\n",
            "estudada pela instituição Universidade Católica De Minas Gerais.\n",
            "\n",
            "Comunidade Santo Antônio, do município Concórdia Do Pará (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 194 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Tomé Nunes, do município Malhada (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 219 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Morada Da Paz, do município Triunfo (RS), da região SUL,\n",
            "é mencionada no artigo de ID 220 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Amazonas.\n",
            "\n",
            "Comunidade Mandira, do município Cananéia (SP), da região SUDESTE,\n",
            "é mencionada no artigo de ID 223 da tabela,\n",
            "estudada pela instituição Université Paris.\n",
            "\n",
            "Comunidade São José Da Serra, do município Valença (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 238 da tabela,\n",
            "estudada pela instituição Centro Federal De Educação Tecnológica Celso Suckow Da Fonseca.\n",
            "\n",
            "Comunidade Pedra Do Sal, do município Rio De Janeiro (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 245 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Estado Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Jequitibá, do município Virgem Da Lapa (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 246 da tabela,\n",
            "estudada pela instituição Faculdade Ciências Da Vida Pontifícia Universidade Católica De Minas Gerais.\n",
            "\n",
            "Comunidade Morro Do Fortunato, do município Garopaba (SC), da região SUL,\n",
            "é mencionada no artigo de ID 248 da tabela,\n",
            "estudada pela instituição Universidade Federal De Santa Catarina Universidade Federal De Santa Catarina.\n",
            "\n",
            "Comunidade Família Bispo, do município Sonora (MS), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 258 da tabela,\n",
            "estudada pela instituição Universidade Federal De Pelotas Universidade Federal Da Grande Dourados.\n",
            "\n",
            "Comunidade Curiaú, do município Macapá (AP), da região NORTE,\n",
            "é mencionada no artigo de ID 263 da tabela,\n",
            "estudada pela instituição Secretaria Municipal De Saúde Do Curiaú Universidade Federal Do Amapá.\n",
            "\n",
            "Comunidade Quartel Do Indaiá, do município Diamantina (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 286 da tabela,\n",
            "estudada pela instituição Universidade Federal Dos Vales Do Jequitinhonha E Mucuri.\n",
            "\n",
            "Comunidade Machadinha, do município Quissamã (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 298 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Rincão Do Couro, do município Piratini (RS), da região SUL,\n",
            "é mencionada no artigo de ID 303 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio Grande.\n",
            "\n",
            "Comunidade Serra Do Evaristo, do município Baturité (CE), da região NORDESTE,\n",
            "é mencionada no artigo de ID 308 da tabela,\n",
            "estudada pela instituição Universidade Estadual Do Ceará Universidade Estadual Do Ceará.\n",
            "\n",
            "Comunidade Morro De São João, do município Santa Rosa Do Tocantins (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 312 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Tocantins Universidade Federal De Goiás.\n",
            "\n",
            "Comunidade Boqueirão, do município Vila Bela Da Santíssima Trindade (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 319 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso Universidad Autónoma Del Estado De Hidalgo.\n",
            "\n",
            "Comunidade Manga, do município Vila Bela Da Santíssima Trindade (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 319 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso Universidad Autónoma Del Estado De Hidalgo.\n",
            "\n",
            "Comunidade Manga, do município Poconé (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 319 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso Universidad Autónoma Del Estado De Hidalgo.\n",
            "\n",
            "Comunidade Retiro, do município Poconé (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 319 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso Universidad Autónoma Del Estado De Hidalgo.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 323 da tabela,\n",
            "estudada pela instituição Universidade De Brasília.\n",
            "\n",
            "Comunidade Capoeiras, do município Macaíba (RN), da região NORDESTE,\n",
            "é mencionada no artigo de ID 324 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio Grande Do Norte Instituto De Ensino E Pesquisa Alberto Santos Dumont.\n",
            "\n",
            "Comunidade Bacabal, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Bairro Alto, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Boa Vista, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Caldeirão, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Campina, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Campina, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Deus Ajude, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Paixão, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Pau Furado, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Providência, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Rosário, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Salvá, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Santa Luzia, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Siricarí, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade São Benedito Da Ponta, do município Salvaterra (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 329 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Morro Redondo, do município Barra Do Bugres (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 332 da tabela,\n",
            "estudada pela instituição Faculdade De Ciências Sociais De Guarantá Do Norte Universidade Do Estado De Mato Grosso.\n",
            "\n",
            "Comunidade Mumbuca, do município Mateiros (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 338 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Tocantins Universidade Do Vale Do Rio Dos Sinos.\n",
            "\n",
            "Comunidade Baixio, do município Barra Do Bugres (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 347 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso.\n",
            "\n",
            "Comunidade Morro Redondo, do município Barra Do Bugres (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 347 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 355 da tabela,\n",
            "estudada pela instituição Pontifícia Universidade Católica De Goiás.\n",
            "\n",
            "Comunidade Bocaina, do município Porto Estrela (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 358 da tabela,\n",
            "estudada pela instituição Universidade Do Estado De Mato Grosso Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Santana, do município Quatis (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 362 da tabela,\n",
            "estudada pela instituição Universidade Federal De Juiz De Fora Universidade De Coimbra Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Itabóca, do município Castanhal (PA), e/ou Inhangapi (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 367 da tabela,\n",
            "estudada pela instituição Instituto Evandro Chagas Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Menino Jesus De Petimandeua, do município Inhangapi (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 367 da tabela,\n",
            "estudada pela instituição Instituto Evandro Chagas Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Alegre, do município Itaguaçu Da Bahia (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 369 da tabela,\n",
            "estudada pela instituição Faculdade Adventista Da Bahia Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Alegre, do município América Dourada (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 369 da tabela,\n",
            "estudada pela instituição Faculdade Adventista Da Bahia Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Moreré, do município Cairu (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 369 da tabela,\n",
            "estudada pela instituição Faculdade Adventista Da Bahia Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Praia Grande, do município Salvador (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 369 da tabela,\n",
            "estudada pela instituição Faculdade Adventista Da Bahia Universidade Federal Da Bahia.\n",
            "\n",
            "Comunidade Castelo, do município Alcântara (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 382 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Castelo, do município Alcântara (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 382 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Maranhão.\n",
            "\n",
            "Comunidade Maria Rosa, do município Iporanga (SP), da região SUDESTE,\n",
            "é mencionada no artigo de ID 383 da tabela,\n",
            "estudada pela instituição Universidade De São Paulo Universidade Federal De Roraima.\n",
            "\n",
            "Comunidade São Benedito, do município Poconé (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 385 da tabela,\n",
            "estudada pela instituição Universidade Federal De Mato Grosso.\n",
            "\n",
            "Comunidade Santa Rita Do Bracuí, do município Angra Dos Reis (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 387 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Pontinha, do município Paraopeba (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 388 da tabela,\n",
            "estudada pela instituição Universidade Federal De Minas Gerais.\n",
            "\n",
            "Comunidade Acaraqui, do município Abaetetuba (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 389 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Castainho, do município Garanhuns (PE), da região NORDESTE,\n",
            "é mencionada no artigo de ID 390 da tabela,\n",
            "estudada pela instituição Universidade Federal De Pernambuco.\n",
            "\n",
            "Comunidade Aldeia, do município Garopaba (SC), da região SUL,\n",
            "é mencionada no artigo de ID 394 da tabela,\n",
            "estudada pela instituição Universidade Federal De Santa Catarina.\n",
            "\n",
            "Comunidade Morro Do Fortunato, do município Garopaba (SC), da região SUL,\n",
            "é mencionada no artigo de ID 394 da tabela,\n",
            "estudada pela instituição Universidade Federal De Santa Catarina.\n",
            "\n",
            "Comunidade Santa Cruz, do município Paulo Lopes (SC), da região SUL,\n",
            "é mencionada no artigo de ID 394 da tabela,\n",
            "estudada pela instituição Universidade Federal De Santa Catarina.\n",
            "\n",
            "Comunidade Castainho, do município Garanhuns (PE), da região NORDESTE,\n",
            "é mencionada no artigo de ID 395 da tabela,\n",
            "estudada pela instituição Universidade Federal De Pernambuco.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 400 da tabela,\n",
            "estudada pela instituição Universidade De Brasília.\n",
            "\n",
            "Comunidade Porto Coris, do município Leme Do Prado (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 401 da tabela,\n",
            "estudada pela instituição Universidade Federal De Viçosa.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 406 da tabela,\n",
            "estudada pela instituição Universidade Católica De Brasília Secretaria Estadual Da Saúde De Monte Alegre De Goiás.\n",
            "\n",
            "Comunidade Capão Verde, do município Poconé (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 422 da tabela,\n",
            "estudada pela instituição Universidade Federal De Mato Grosso.\n",
            "\n",
            "Comunidade Brejo Dos Crioulos, do município São João Da Ponte (MG), Varzelândia (MG), e/ou Verdelândia (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 424 da tabela,\n",
            "estudada pela instituição Universidade Federal De Viçosa Instituto Nacional De Colonização E Reforma Agrária.\n",
            "\n",
            "Comunidade Pedra Do Sal, do município Rio De Janeiro (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 427 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Caiana Dos Crioulos, do município Alagoa Grande (PB), da região NORDESTE,\n",
            "é mencionada no artigo de ID 428 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Paraíba.\n",
            "\n",
            "Comunidade Lapinha, do município Matias Cardoso (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 430 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Comunidade Lapinha, do município Cônego Marinho (MG), da região SUDESTE,\n",
            "é mencionada no artigo de ID 430 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Comunidade Almeidas, do município Silvânia (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 434 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Goiás.\n",
            "\n",
            "Comunidade Jardim Cascata, do município Aparecida De Goiânia (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 434 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Goiás.\n",
            "\n",
            "Comunidade Pedra Do Sal, do município Rio De Janeiro (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 447 da tabela,\n",
            "estudada pela instituição Universidade Nova De Lisboa.\n",
            "\n",
            "Comunidade São José Da Serra, do município Valença (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 448 da tabela,\n",
            "estudada pela instituição Centro De Ensino Superior De Valença Universidade Estácio De Sá.\n",
            "\n",
            "Comunidade Curralinho Do Pontal, do município Brejinho De Nazaré (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 451 da tabela,\n",
            "estudada pela instituição Associação Dos Falcêmicos Do Estado Do Tocantins Universidade Federal Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Comunidade Córrego Fundo, do município Brejinho De Nazaré (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 451 da tabela,\n",
            "estudada pela instituição Associação Dos Falcêmicos Do Estado Do Tocantins Universidade Federal Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Comunidade Malhadinha, do município Brejinho De Nazaré (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 451 da tabela,\n",
            "estudada pela instituição Associação Dos Falcêmicos Do Estado Do Tocantins Universidade Federal Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Comunidade Manoel João, do município Brejinho De Nazaré (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 451 da tabela,\n",
            "estudada pela instituição Associação Dos Falcêmicos Do Estado Do Tocantins Universidade Federal Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 452 da tabela,\n",
            "estudada pela instituição Universidade De Brasília.\n",
            "\n",
            "Comunidade Pedra Do Sal, do município Rio De Janeiro (RJ), da região SUDESTE,\n",
            "é mencionada no artigo de ID 460 da tabela,\n",
            "estudada pela instituição Universidade Do Estado Do Rio De Janeiro.\n",
            "\n",
            "Comunidade Manoel Do Rêgo, do município Canguçu (RS), da região SUL,\n",
            "é mencionada no artigo de ID 461 da tabela,\n",
            "estudada pela instituição Universidade Federal De Sergipe.\n",
            "\n",
            "Comunidade Casinhas, do município Jeremoabo (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 469 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Feira De Santana Universidade Do Estado Da Bahia.\n",
            "\n",
            "Comunidade Lagoa Da Pedra, do município Arraias (TO), da região NORTE,\n",
            "é mencionada no artigo de ID 480 da tabela,\n",
            "estudada pela instituição Rede Pública Do Estado Do Tocantins Universidade Federal Do Tocantins.\n",
            "\n",
            "Comunidade Filipa, do município Itapecuru-Mirim (MA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 482 da tabela,\n",
            "estudada pela instituição Universidade Estadual De Santa Cruz.\n",
            "\n",
            "Comunidade Saracura, do município Santarém (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 483 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Pedras Negras, do município Alta Floresta D Oeste (RO), e/ou São Francisco Do Guaporé (RO), da região NORTE,\n",
            "é mencionada no artigo de ID 484 da tabela,\n",
            "estudada pela instituição Universidade Federal De Rondônia Centro De Pesquisa Em Medicina Tropical Instituto De Pesquisas Em Patologias Tropicais Universidade De São Paulo.\n",
            "\n",
            "Comunidade Água Morna, do município Curiúva (PR), da região SUL,\n",
            "é mencionada no artigo de ID 486 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Paraná.\n",
            "\n",
            "Comunidade Giral Grande, do município Maragogipe (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 490 da tabela,\n",
            "estudada pela instituição Faculdade Da Cidade De Salvador.\n",
            "\n",
            "Comunidade Cambará, do município Cachoeira Do Sul (RS), da região SUL,\n",
            "é mencionada no artigo de ID 496 da tabela,\n",
            "estudada pela instituição N D.\n",
            "\n",
            "Comunidade Mata Cavalo, do município Nossa Senhora Do Livramento (MT), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 505 da tabela,\n",
            "estudada pela instituição Universidade De São Paulo.\n",
            "\n",
            "Comunidade Tijuaçu, do município Senhor Do Bonfim (BA), Antônio Gonçalves (BA), e/ou Filadélfia (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 522 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Bahia.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 524 da tabela,\n",
            "estudada pela instituição Instituto Pró Fundação Leopold Sedar Senghor Universidade De Brasília Universidade Federal Do Rio Grande Do Sul.\n",
            "\n",
            "Comunidade São Miguel, do município Restinga Seca (RS), da região SUL,\n",
            "é mencionada no artigo de ID 524 da tabela,\n",
            "estudada pela instituição Instituto Pró Fundação Leopold Sedar Senghor Universidade De Brasília Universidade Federal Do Rio Grande Do Sul.\n",
            "\n",
            "Comunidade Caiana Dos Crioulos, do município Alagoa Grande (PB), da região NORDESTE,\n",
            "é mencionada no artigo de ID 525 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Paraíba.\n",
            "\n",
            "Comunidade Carmo, do município São Roque (SP), da região SUDESTE,\n",
            "é mencionada no artigo de ID 528 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Bahia Universidade Católica Do Salvador.\n",
            "\n",
            "Comunidade Santana Do Arari, do município Ponta De Pedras (PA), da região NORTE,\n",
            "é mencionada no artigo de ID 532 da tabela,\n",
            "estudada pela instituição Universidade Federal Do Pará.\n",
            "\n",
            "Comunidade Bananal, do município Itamari (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 533 da tabela,\n",
            "estudada pela instituição Universidade De São Paulo Laboratório Frischmann Aisengart Universidade Estadual Do Sudoeste Da Bahia Universidade Federal Do Paraná Universidade Estadual De Feira De Santana.\n",
            "\n",
            "Comunidade Bananal, do município Rio De Contas (BA), da região NORDESTE,\n",
            "é mencionada no artigo de ID 533 da tabela,\n",
            "estudada pela instituição Universidade De São Paulo Laboratório Frischmann Aisengart Universidade Estadual Do Sudoeste Da Bahia Universidade Federal Do Paraná Universidade Estadual De Feira De Santana.\n",
            "\n",
            "Nome ambíguo Kalunga, do município Cavalcante (GO), Monte Alegre De Goiás (GO), e/ou Teresina De Goiás (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 536 da tabela,\n",
            "estudada pela instituição Universidade De Brasília.\n",
            "\n",
            "Comunidade Pombal, do município Santa Rita Do Novo Destino (GO), da região CENTRO-OESTE,\n",
            "é mencionada no artigo de ID 538 da tabela,\n",
            "estudada pela instituição Universidade Federal Da Bahia.\n",
            "\n",
            "=== SEGUNDA RODADA: MENÇÕES REGIONAIS ===\n",
            "\n",
            "Quilombos do sudoeste de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 10 da tabela,\n",
            "estudados pela instituição N D.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 23 da tabela,\n",
            "estudados pela instituição N D.\n",
            "\n",
            "Quilombos de todas as regiões de Mato Grosso, na região Centro-Oeste,\n",
            "são mencionados no artigo de ID 31 da tabela,\n",
            "estudados pela instituição N D.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 36 da tabela,\n",
            "estudados pela instituição N D.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 58 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 82 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do interior de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 122 da tabela,\n",
            "estudados pela instituição Universidade Federal Da Bahia.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 208 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros Instituto Federal Do Norte De Minas Gerais.\n",
            "\n",
            "Quilombos do região de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 267 da tabela,\n",
            "estudados pela instituição Universidade Federal Da Bahia Universidade Estadual De Feira De Santana Universidade Estadual Do Sudoeste Da Bahia Universidade Do Estado Da Bahia.\n",
            "\n",
            "Quilombos do região de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 293 da tabela,\n",
            "estudados pela instituição Universidade Estadual Do Sudoeste Da Bahia Universidade De Brasília Universidade Do Estado Da Bahia Universidade Federal De Santa Catarina Grupo De Estudos Pesquisa E Extensão Em Educação Cultura E Saúde.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 314 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do interior de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 317 da tabela,\n",
            "estudados pela instituição Prefeitura Municipal De Vitória Da Conquista Universidade Federal Da Bahia.\n",
            "\n",
            "Quilombos do sudoeste de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 363 da tabela,\n",
            "estudados pela instituição Universidade Federal Da Bahia Universidade Federal De Minas Gerais.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 373 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 405 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do sudoeste de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 413 da tabela,\n",
            "estudados pela instituição Universidade Federal De Minas Gerais Universidade Federal Da Bahia.\n",
            "\n",
            "Quilombos do sudoeste de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 419 da tabela,\n",
            "estudados pela instituição Universidade Federal De Minas Gerais Universidade Federal Da Bahia.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 433 da tabela,\n",
            "estudados pela instituição Universidade Estadual De Montes Claros Faculdades Unidas Do Norte De Minas.\n",
            "\n",
            "Quilombos do sudoeste de Bahia, na região Nordeste,\n",
            "são mencionados no artigo de ID 439 da tabela,\n",
            "estudados pela instituição Universidade Federal De Minas Gerais Universidade Federal Da Bahia.\n",
            "\n",
            "Quilombos do norte de Minas Gerais, na região Sudeste,\n",
            "são mencionados no artigo de ID 457 da tabela,\n",
            "estudados pela instituição Faculdades Unidas Do Norte De Minas Universidade Estadual De Montes Claros.\n",
            "\n",
            "Quilombos do norte de Espírito Santo, na região Sudeste,\n",
            "são mencionados no artigo de ID 504 da tabela,\n",
            "estudados pela instituição Universidade Federal Do Espírito Santo.\n",
            "\n",
            "=== RESUMO DOS RESULTADOS ===\n",
            "\n",
            "Foram encontradas 142 menções a comunidades quilombolas específicas em 103 artigos únicos.\n",
            "Foram identificados 21 artigos adicionais que mencionam quilombos/comunidades de forma regional.\n",
            "Total de artigos com menções relevantes: 124\n",
            "\n",
            "CSV com 142 registros detalhados exportado para: /content/drive/My Drive/estudo_quilombos_organizado/resultados_detalhados.csv\n",
            "Nova cópia dos artigos salva em: /content/drive/My Drive/estudo_quilombos_organizado/artigos_final.csv\n",
            "  - 142 linhas para artigos com comunidades específicas\n",
            "  - 21 linhas para artigos com menções regionais\n",
            "  - 418 linhas para artigos sem comunidades\n",
            "Processamento concluído. Últimos quatro caracteres da coluna 13 adicionados\n",
            "como nova coluna 'ANO DA PORTARIA' em: /content/drive/My Drive/estudo_quilombos_organizado/artigos_final.csv\n",
            "\n",
            "Análise concluída com 124 correspondências encontradas.\n",
            "Resultados salvos em:\n",
            "  - Texto: /content/drive/My Drive/estudo_quilombos_organizado/resultados.txt\n",
            "  - CSV detalhado: /content/drive/My Drive/estudo_quilombos_organizado/resultados_detalhados.csv\n",
            "  - Artigos com comunidades: /content/drive/My Drive/estudo_quilombos_organizado/artigos_final.csv\n"
          ]
        }
      ],
      "source": [
        "#LABORATÓRIO: MensureLab - UFPA.\n",
        "#AUTORES: @RamiroKord; @Josafha-pereira (GitHub)\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from typing import List, Dict, Optional, Set, Tuple\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "from contextlib import redirect_stdout\n",
        "import io\n",
        "import csv\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def load_communities_csv(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load communities CSV file.\"\"\"\n",
        "    return pd.read_csv(file_path, sep=';', encoding='latin-1')\n",
        "\n",
        "\n",
        "def load_articles_csv(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load articles CSV file.\"\"\"\n",
        "    return pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
        "\n",
        "\n",
        "def get_state_name(uf: str) -> str:\n",
        "    \"\"\"Map UF codes to full state names.\"\"\"\n",
        "    UF_STATES = {\n",
        "        \"ac\": \"acre\", \"al\": \"alagoas\", \"am\": \"amazonas\", \"ap\": \"amapá\",\n",
        "        \"ba\": \"bahia\", \"ce\": \"ceará\", \"df\": \"distrito federal\", \"es\": \"espírito santo\",\n",
        "        \"go\": \"goiás\", \"ma\": \"maranhão\", \"mg\": \"minas gerais\", \"ms\": \"mato grosso do sul\",\n",
        "        \"mt\": \"mato grosso\", \"pa\": \"pará\", \"pb\": \"paraíba\", \"pe\": \"pernambuco\",\n",
        "        \"pi\": \"piauí\", \"pr\": \"paraná\", \"rj\": \"rio de janeiro\", \"rn\": \"rio grande do norte\",\n",
        "        \"ro\": \"rondônia\", \"rr\": \"roraima\", \"rs\": \"rio grande do sul\", \"sc\": \"santa catarina\",\n",
        "        \"se\": \"sergipe\", \"sp\": \"são paulo\", \"to\": \"tocantins\"\n",
        "    }\n",
        "    return UF_STATES.get(uf.strip().lower(), \"\")\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Clean and normalize text.\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', text).strip().lower() # transforma espaços duplos, com tab, etc.. em \"branco\" (\" \") e deixa o texto minusculo\n",
        "\n",
        "\n",
        "def remove_diacritics(text: str) -> str:\n",
        "    \"\"\"Remove diacritical marks from text.\"\"\"\n",
        "    normalized = unicodedata.normalize('NFD', text) # normalized recebe a separaçãp da letra do acento, deixando no padrão NFD\n",
        "    return ''.join(c for c in normalized if not unicodedata.combining(c)) # deixa apenas a parte que não tem acento\n",
        "\n",
        "\n",
        "def normalize_apostrophes(text: str) -> List[str]:\n",
        "    \"\"\"Create variants with different apostrophe treatments.\"\"\"\n",
        "    if not any(char in text for char in \"'`´\"): # vefica se text tem algum \"'\", \"`\" ou \"´\". Se não tiver, então ele retorna text (nada a tratar), se não, continua\n",
        "        return [text]\n",
        "\n",
        "    apostrophe_pattern = re.compile(r'[\\'`´]') #cria um padrão que corresponde aos caracteres \"'\", \"`\" ou \"´\"\n",
        "    variants = [] # lista (agora vazia) pra armazenar versões diferentes do texto com apocrifos\n",
        "\n",
        "    # Standard apostrophe, backtick, acute accent, space, removed\n",
        "    for replacement in [\"'\", \"`\", \"´\", \" \", \"\"]: # itera sobre a lista de possibilidades de substituições para os apocrifos\n",
        "        variant = apostrophe_pattern.sub(replacement, text) # substitui todos os apocrifos no texto pela substituição atual de replacement e guarda em variant\n",
        "                                                            # fica uma lista como por ex: \"d'agua\" vira [\"d'agua\", \"dagua\", \"d´agua\", \"d agua\", \"dagua\"] na lista variant\n",
        "        if replacement == \" \":\n",
        "            variant = re.sub(r'\\s+', ' ', variant).strip() # substitui espaço duplo, tab, etc.. por um espaço em branco.\n",
        "        variants.append(variant) # vai ser adicionado em variants a lista de variant\n",
        "\n",
        "    return variants #retorna variants\n",
        "\n",
        "\n",
        "def normalize_hyphens(text: str) -> Tuple[str, str]:\n",
        "    \"\"\"Create hyphenated and non-hyphenated versions.\"\"\"\n",
        "    hyphenated = re.sub(r'\\s+', '-', text) # substitui espaços, quebra de linha, etc.. por \"-\" -> antes: peixe boi. agr: peixe-boi\n",
        "    non_hyphenated = re.sub(r'-', ' ', text) # substitui \"-\"\" por um espaço em branco -> antes: peixe-boi. agr: peixe boi\n",
        "    non_hyphenated = re.sub(r'\\s+', ' ', non_hyphenated).strip() # substitui espaços duplos, tabs, etc.. em um espaço em branco normal (unico)\n",
        "    return hyphenated, non_hyphenated # retorna uma dupla com hyphernated e non_hyphernated\n",
        "\n",
        "\n",
        "def split_communities(text: str) -> List[str]:\n",
        "    \"\"\"Split community names by delimiters.\"\"\"\n",
        "    cleaned_text = clean_text(text) # cleaned_text recebe o texto sem espaços duplos, tabs, etc... apenas com espaços normais \" \" e deixa o texto minusculo\n",
        "\n",
        "    pattern = re.compile(r'\\b[eE]\\b|[(),:/]') # padrão pra identificar \"e\" ou \"E\", \"(\"\", \")\"\", \",\", \":\", ou \"/\"\n",
        "\n",
        "    e_count = sum(1 for m in re.finditer(r'\\b[eE]\\b', cleaned_text)) # conta a quantidade de vezes q \"e\" ou \"E\" (isolada) aparecem no texto\n",
        "\n",
        "    # Special case: exactly two names separated by a single \"E\"\n",
        "    if e_count == 1 and \",\" not in cleaned_text: # SE a quantidade de \"e\" no texto for 1 e não tiver virgula no texto limpo (cleaned_text)\n",
        "        parts = [part.strip() for part in pattern.split(cleaned_text) if part.strip()] # divide o texto limpo e cria uma lista com os nomes (ex: A e B -> [\"A\", \"B\"]\n",
        "        if len(parts) == 2: # se a divisão foi em duas partes... (ex: A e B -> [\"A\", \"B\"]\n",
        "            return parts + [cleaned_text] # retorna parts (nome dividido) e o texto original (sem dividir). (ex: A e B -> [\"A\", \"B\", \"A e B\"]\n",
        "\n",
        "    return [part.strip() for part in pattern.split(cleaned_text) if part.strip()] # Retorna a lista de comunidades dividido pelos delimitadores, com espaços e espaços extras removidos\n",
        "\n",
        "\n",
        "def split_municipalities(text: str) -> List[str]:\n",
        "    \"\"\"Split municipality names by delimiters.\"\"\"\n",
        "    return [m.strip() for m in re.split(r'[|/]', text)] # retorna uma lista com o texto divido usando os delimitadoeres \"|\" e \"/\".\n",
        "                                                        #  ex: São Paulo/Rio|Salvador -> [\"São Paulo\", \"Rio\", \"Salvador\"]\n",
        "\n",
        "\n",
        "def clean_article_text(text: str) -> str:\n",
        "    \"\"\"Clean article text for searching.\"\"\"\n",
        "    cleaned_text = re.sub(r'[^\\w\\s]', ' ', str(text)).lower() # remove caracteres especiais e converte o texto pra minusculo\n",
        "    return re.sub(r'\\s+', ' ', cleaned_text).strip() # substitui espaço duplo, tab, etc.. por um espaço em branco \" \"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA STRUCTURES\n",
        "# =============================================================================\n",
        "\n",
        "class Community:\n",
        "    \"\"\"Represents a quilombola community.\"\"\"\n",
        "\n",
        "    def __init__(self, id: int, name: str, municipality: str, uf: str, state: str, region: str,\n",
        "                 original_municipality_str: str = None):\n",
        "          '''\n",
        "                           exemplo de uso:\n",
        "\n",
        "        community = Community(id=1, name=\"Quilombo Kalunga\", municipality=\"Cavalcante\", uf=\"GO\",\n",
        "                    state=\"Goiás\", region=\"Centro-Oeste\", original_municipality_str=\"\"Cavalcante|Goiânia\")\n",
        "\n",
        "          '''\n",
        "\n",
        "        # para ser uma \"comunidade quilombola\", precisa ter esses atributos:\n",
        "          self.id = id # id da comunidade\n",
        "          self.name = name # nome da comunidade\n",
        "          self.municipality = municipality # municipio da comunidade\n",
        "          self.uf = uf # sigla da unidade federativa (ex Pará -> PA)\n",
        "          self.state = state #  estado da comunidade -> convertido a partir da uf pela função get_state_name().\n",
        "          self.region = region # região (ex: norte, nordeste, etc..) da comunidade\n",
        "          self.original_municipality_str = original_municipality_str # municipio/Sigla-Do-Estado\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f\"{self.name.title()}, {self.municipality.title()} ({self.uf.upper()})\" #representação formatada do objeto em questão, para depuração, exibição ou relatórios\n",
        "                                                                                       # ex: Quilombo Kalunga, Cavalcante (GO)\n",
        "\n",
        "\n",
        "class Article:\n",
        "    \"\"\"Represents an academic article with search capabilities.\"\"\"\n",
        "\n",
        "    def __init__(self, id: int, title: str, title_alt1: str, title_alt2: str,\n",
        "                 keywords: str, keywords_alt: str, abstract: str, abstract_alt1: str, abstract_alt2: str,\n",
        "                 institution: str):\n",
        "       \"\"\"\n",
        "                                   exemplo de uso:\n",
        "\n",
        "                                    article = Article(\n",
        "                                    id=2,\n",
        "                                    title=\"Estudo sobre Quilombos\",\n",
        "                                    title_alt1=\"Study on Quilombos\",\n",
        "                                    title_alt2=\"Estudio sobre Quilombos\",\n",
        "                                    keywords=\"quilombo, cultura\",\n",
        "                                    keywords_alt=\"afrodescendant, culture\",\n",
        "                                    abstract=\"Comunidades quilombolas...\",\n",
        "                                    abstract_alt1=\"Quilombola communities...\",\n",
        "                                    abstract_alt2=\"Comunidades quilombolas...\",\n",
        "                                    institution=\"USP\"\n",
        ")\n",
        ")\n",
        "\n",
        "\n",
        "       \"\"\"\n",
        "\n",
        "       # para ser um artigo, precisa desses atributos:\n",
        "       self.id = id # id do artigo\n",
        "\n",
        "       # os artigos estão mostrados em 3 colunas diferentes, sendo portugues, ingles e espanhol. Porém acaba se misturando. ex: title em portugues na coluna espanhol\n",
        "       self.title = title # 1 coluna de titulo\n",
        "       self.title_alt1 = title_alt1 # 2 coluna de titulo\n",
        "       self.title_alt2 = title_alt2 #  3 coluna de titulo\n",
        "\n",
        "       # as palavras chave estão em 2 colunas diferentes, sendo em 2 linguas. Porém acaba se misturando igual artigos. ex: keyword em portugues na coluna espanhol\n",
        "       self.keywords = keywords # 1 coluna keyword\n",
        "       self.keywords_alt = keywords_alt # 2 coluna keyword\n",
        "\n",
        "       # os resumos/abstracts estão em 3 colunas diferentes, sendo em 3 linguas. Porém acaba se misturando igual artigos. ex: abstract em portugues na coluna ingles\n",
        "       self.abstract = abstract # 1 coluna de abstract\n",
        "       self.abstract_alt1 = abstract_alt1 # 2 coluna de abstract\n",
        "       self.abstract_alt2 = abstract_alt2 # 3 coluna de abstract\n",
        "       self.institution = institution # instituição vinculada ao artigo -> universidade ou organização\n",
        "\n",
        "        # inicializa atributos privados (pois tem o \"_\" apos \"sef.\")\n",
        "        # essas variaveis guardam todas as informações do artigo em espefico (ex: artigo id 2), porém de forma concatenada.\n",
        "\n",
        "# ==================================================================================================================================================================================\n",
        "      # FUNCIONAMENTO DA LOGICA DAS VARIAVEIS ABAIXO:\n",
        "\n",
        "        #Quando o programa faz uma busca (ex.: article.has_term_diacritical_insensitive(\"Quilombo Kalunga\") em QuilombolaAnalyzer._check_community_match):\n",
        "        #nota: suponha que está no artigo de id 2, do exemplo mais acima.\n",
        "\n",
        "  #O método has_term_diacritical_insensitive chama get_normalized_terms_dict, que verifica:\n",
        "   #se _normalized_terms_dict é None:\n",
        "     #como é None, get_normalized_terms_dict chama get_normalized_full_text, que verifica:\n",
        "      #se _normalized_full_text é None:\n",
        "        #Como _normalized_full_text é None, ele chama get_full_text, que concatena os campos:\n",
        "\n",
        "#_full_text vira: \"Estudo sobre São Paulo Study on Sao Paulo Estudio sobre São Paulo quilombo, cultura afrodescendant, culture Comunidades quilombolas em São Paulo... Quilombola communities in Sao Paulo... Comunidades quilombolas en São Paulo...\".\n",
        "\n",
        "\n",
        "#get_normalized_full_text aplica remove_diacritics (tirar acentos do texto):\n",
        "\n",
        "#_normalized_full_text vira: \"Estudo sobre Sao Paulo Study on Sao Paulo Estudio sobre Sao Paulo quilombo, cultura afrodescendant, culture Comunidades quilombolas em Sao Paulo... Quilombola communities in Sao Paulo... Comunidades quilombolas en Sao Paulo...\".\n",
        "\n",
        "\n",
        "#get_normalized_terms_dict chama _build_terms_dict com _normalized_full_text, criando:\n",
        "#python_normalized_terms_dict = {\n",
        "#    \"estudo\": True, \"sobre\": True, \"sao\": True, \"paulo\": True,\n",
        "#    \"quilombo\": True, \"cultura\": True, \"afrodescendant\": True,\n",
        "#    \"sao paulo\": True, \"sao-paulo\": True, ...\n",
        "#}\n",
        "\n",
        "#has_term_diacritical_insensitive verifica se \"quilombo kalunga\" (normalizado para \"quilombo kalunga\") está em _normalized_terms_dict. Como não está, tenta variantes (ex.: com hífens) e, como última tentativa, verifica _normalized_full_text.\n",
        "\n",
        "# =========================================================================================================================================================================================================\n",
        "\n",
        "       self._full_text = None # tem as informações do artigo (os atributos, title, abstract, etc...), coluna por coluna, e junta, concatena tudo em uma string\n",
        "       self._normalized_full_text = None # faz a mesma coisa que _full_text, porém de forma normalizada (sem acentos)\n",
        "       self._terms_dict = None # cria um dicionario com \"false\" e \"true\", pra saber se a palavra está na string concatenada. com base em full_text\n",
        "       self._normalized_terms_dict = None #  cria um dicionario com \"false\" e \"true\", pra saber se a palavra está na string concatenada. com base em _normalized_full_text\n",
        "\n",
        "    def get_full_text(self) -> str:\n",
        "        \"\"\"Get concatenated text of all fields.\"\"\"\n",
        "        if self._full_text is None: # verifica se o full text é none (vazio)\n",
        "            # se for verdadeiro, full_text vai receber as informações do artigo e vai concatenar todas elas\n",
        "            self._full_text = \" \".join([\n",
        "                self.title, self.title_alt1, self.title_alt2,\n",
        "                self.keywords, self.keywords_alt, self.abstract,\n",
        "                self.abstract_alt1, self.abstract_alt2\n",
        "            ])\n",
        "        return self._full_text # retorna o texto contendo as informações do artigo em uma só string, concatenado.\n",
        "\n",
        "    def get_normalized_full_text(self) -> str:\n",
        "        \"\"\"Get full text with diacritics removed.\"\"\"\n",
        "        if self._normalized_full_text is None: # verifica se _normalized_full_text é none (vazio)\n",
        "            # se for verdadeiro, _normalized_full_text vai receber a função que remove  acentos com o argumento sendo o \"ful_text\".\n",
        "            self._normalized_full_text = remove_diacritics(self.get_full_text()) # _normalized_full_text vai reveber o texto normalizado de full_text\n",
        "        return self._normalized_full_text # retorna o texto normalizado\n",
        "\n",
        "    def _build_terms_dict(self, text: str) -> Dict[str, bool]:\n",
        "        \"\"\"Build terms dictionary for fast lookup.\"\"\"\n",
        "\n",
        "        # propisito: cria um \"índice\" do texto de um artigo para permitir buscas rápidas de palavras ou frases que estão presentes nele.\n",
        "\n",
        "        terms_dict = defaultdict(bool) # cria um dicionario que retorna false pra palavras inexistentes. ex: terms_dict[\"inexistente\"], retorna False\n",
        "\n",
        "        # Single words\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower()) # words (lista) recebe as palavras encontradas de forma individual. ex: \"sao paulo e uma cidade\" -> [sao, paulo, e, uma, cidade]\n",
        "        for word in words: # faz um loop de word em words\n",
        "            terms_dict[word] = True # se word for existente retorna true, se não existe, retorna false\n",
        "\n",
        "        # Multi-word phrases\n",
        "        phrases = re.findall(r'\\b[\\w\\s-]+\\b', text.lower()) # phrases (lista) recebe frases e palavras com espaço e hifem incluidos\n",
        "        for phrase in phrases:\n",
        "            phrase = phrase.strip() # strip remove cada espaço no começo e no fim  da frase\n",
        "            if ' ' in phrase or '-' in phrase: # verfica se tem espaço ou hifem na frase, se tiver, continua o loop\n",
        "                terms_dict[phrase] = True # se tiver, retorna true, se não (inexistente), false.\n",
        "\n",
        "                # Add hyphen variants\n",
        "                hyphenated, non_hyphenated = normalize_hyphens(phrase) # a função normalize_hyphens retorna uma dupla com 2 trocando: espaços por hifem, hifem por espaços.\n",
        "                terms_dict[hyphenated] = True # ex: frase \"bom dia\" -> bom-dia\n",
        "                terms_dict[non_hyphenated] = True # ex: frase \"bom-dia\" -> bom dia\n",
        "\n",
        "                # Add apostrophe variants\n",
        "                if any(char in phrase for char in \"'`´\"): # Se tiver qualquer caractere em \"phase\" com  \"'`´\"\n",
        "                    for variant in normalize_apostrophes(phrase): # faz um loop da lista variant em normalize_apostrophes (q é uma função para fazer variantes de apostrofos)\n",
        "                        terms_dict[variant] = True # se não for \"inexistente\" caracteres com  \"'`´\", então retorna true\n",
        "\n",
        "        return terms_dict # retorna o terms_dict já pronto com os \"true\" e \"false\" de palavras que tem no texto\n",
        "\n",
        "    def get_terms_dict(self) -> Dict[str, bool]:\n",
        "        \"\"\"Get terms dictionary for normal text.\"\"\"\n",
        "        if self._terms_dict is None: # se o _terms_dict for vazio (sem nada)\n",
        "            self._terms_dict = self._build_terms_dict(self.get_full_text()) # terms_dict vai receber o resultado do texto na função que pega os termos dict (true e false) no texto\n",
        "        return self._terms_dict # retorna termos dict\n",
        "\n",
        "    def get_normalized_terms_dict(self) -> Dict[str, bool]:\n",
        "        \"\"\"Get terms dictionary for normalized text.\"\"\"\n",
        "        # Note: muitos dos codigos abaixo são quase que uma copia da f8unção de cima, só mudando ser normalizado ou não\n",
        "        if self._normalized_terms_dict is None: # Se _normalized_terms_dict for vazio\n",
        "            self._normalized_terms_dict = self._build_terms_dict(self.get_normalized_full_text()) # _normalized_terms_dict vai receber o resultado do texto na função que pega os termos dict (true e false) no texto\n",
        "        return self._normalized_terms_dict # retorna terms dict normalizado (se acentos)\n",
        "\n",
        "    def has_term(self, term: str) -> bool:\n",
        "        \"\"\"Check if term exists in article.\"\"\"\n",
        "        # Direct lookup\n",
        "        if self.get_terms_dict().get(term, False): # verifica se existe o \"term\" no dicionario, caso tenha, retorns true. Caso \"false\", não entra na condicional.\n",
        "                                                   # a.get(arg1, arg2) -> get verifica se tem o arg1 no dicionario a, se tiver, reotorna ele, se não tiver retorna o arg2\n",
        "            return True # se tiver o tem no get_termos_dict, retorna true.\n",
        "\n",
        "        # Try variants for complex terms\n",
        "        if '-' in term or ' ' in term or any(char in term for char in \"'`´\"): # verifica se tem  em term \"-\" ou \" ' ' \" ou algum apotrofo \"'`´\"\n",
        "            # Hyphen variants\n",
        "            if '-' in term or ' ' in term: # se tiver \"-\" ou \" ' ' \" em terms, a condicional vai ser verdadeira\n",
        "                hyphenated, non_hyphenated = normalize_hyphens(term) # retorna 2 versões, uma só com hifem e a outra só com espaço\n",
        "                if (self.get_terms_dict().get(hyphenated, False) or\n",
        "                    self.get_terms_dict().get(non_hyphenated, False)): # verificação rapida, pra saber se tem em terms_dict tems só com hifem ou só com espaço\n",
        "                    return True # se sim (pegou o terms com ou sem hifem no dicionario), retorna true\n",
        "\n",
        "            # Apostrophe variants\n",
        "            if any(char in term for char in \"'`´\"): # se tiver algum apostrofo  \"'`´\" em term, a condicional vai ser verdadeira\n",
        "                for variant in normalize_apostrophes(term): # faz um loop da lista variant em normalize_apostrophes (q é a função para fazer variantes de apostrofos)\n",
        "                    if self.get_terms_dict().get(variant, False): # verifica se existe o \"term\" no dicionario, caso tenha, retorns true. Caso \"false\", não entra na condicional.\n",
        "                                                                  # nota: no inicio da função foi explicado a logica do \"get(arg1, arg2)\"\n",
        "                                                                  # nota 2: note que essa condição é satisfeita se tiver apostrofo em tems\n",
        "                        return True # se sim (pegou alguma variação de aposcrofo de term  no dicionario), retorna true\n",
        "\n",
        "            # Fallback to substring search\n",
        "            hyphenated, non_hyphenated = normalize_hyphens(term)\n",
        "            return (hyphenated in self.get_full_text() or\n",
        "                   non_hyphenated in self.get_full_text()) # se nenhuma das condições acima foram satisfeitas, retorna o termo com hifem ou sem hifem no texto \"completo\"\n",
        "                                                           # não tenho certeza se é isso, tá bem confuso esse trecho\n",
        "\n",
        "        return False # se nenhuma condição acima for satisfeita, retorna false\n",
        "\n",
        "    def has_term_diacritical_insensitive(self, term: str) -> bool:\n",
        "        \"\"\"Check if term exists ignoring diacritics.\"\"\"\n",
        "\n",
        "        # Note: muitos dos codigos abaixo são quase que uma copia da f8unção de cima, só mudando ser normalizado ou não\n",
        "        normalized_term = remove_diacritics(term) # normalized_term recebe o \"term\" sem acentos\n",
        "\n",
        "        # Direct lookup\n",
        "        if self.get_normalized_terms_dict().get(normalized_term, False): # verifica se normalized_tem está no dicionario _normalized_terms_dict, se sim, condição feita.\n",
        "                                                                         # se não, false\n",
        "            return True # condição for verdadeira, retorna true\n",
        "\n",
        "        # Try variants for complex terms\n",
        "        if '-' in normalized_term or ' ' in normalized_term or any(char in normalized_term for char in \"'`´\"): # verifica se tem  em normalized_term \"-\" ou \" ' ' \" ou\n",
        "                                                                                                               # qualquer apotrofo \"'`´\"\n",
        "            # Hyphen variants\n",
        "            if '-' in normalized_term or ' ' in normalized_term:  # se tiver \"-\" ou \" ' ' \" em normalized_term, a condicional vai ser verdadeira\n",
        "                hyphenated, non_hyphenated = normalize_hyphens(normalized_term) # retorna 2 versões, uma só com hifem e a outra só com espaço\n",
        "                if (self.get_normalized_terms_dict().get(hyphenated, False) or\n",
        "                    self.get_normalized_terms_dict().get(non_hyphenated, False)):  # verificação rapida, pra saber se tem em terms_dict tems só com hifem ou só com espaço\n",
        "                    return True  # se sim (pegou o terms com ou sem hifem no dicionario), retorna true\n",
        "\n",
        "            # Apostrophe variants\n",
        "            if any(char in normalized_term for char in \"'`´\"): # se tiver algum apostrofo  \"'`´\" em term, a condicional vai ser verdadeira\n",
        "                for variant in normalize_apostrophes(normalized_term): # faz um loop da lista variant em normalize_apostrophes (q é a função para fazer variantes de apostrofos)\n",
        "                    if self.get_normalized_terms_dict().get(variant, False): # verifica se existe o \"term\" no dicionario, caso tenha, retorns true. Caso \"false\", não entra na condicional.\n",
        "                                                                             # nota: no inicio da função foi explicado a logica do \"get(arg1, arg2)\"\n",
        "                                                                             # nota 2: note que essa condição é satisfeita se tiver apostrofo em tems\n",
        "                        return True # se sim (pegou alguma variação de aposcrofo de term  no dicionario), retorna true\n",
        "\n",
        "            # Fallback to substring search\n",
        "            hyphenated, non_hyphenated = normalize_hyphens(normalized_term)\n",
        "            return (hyphenated in self.get_normalized_full_text() or\n",
        "                   non_hyphenated in self.get_normalized_full_text()) # se nenhuma das condições acima foram satisfeitas, retorna o termo com hifem ou sem hifem no texto \"completo\"\n",
        "                                                                      # não tenho certeza se é isso, tá bem confuso esse trecho\n",
        "\n",
        "        return False # se nenhuma condição acima for satisfeita, retorna false\n",
        "\n",
        "\n",
        "class RegionalMatch:\n",
        "    \"\"\"Represents a regional quilombo mention.\"\"\"\n",
        "\n",
        "    def __init__(self, internal_region: str, state_name: str, uf: str, country_region: str,\n",
        "                 community_term: str, all_regions_term: str = None):\n",
        "\n",
        "        # para ser uma região, precisa desses atributos:\n",
        "\n",
        "        self.internal_region = internal_region # região interna de um estado que a comunidade foi pesquisada. ex: sertão da bahia\n",
        "        self.state_name = state_name # nome do estado\n",
        "        self.uf = uf # sigla do estado\n",
        "        self.country_region = country_region # região. ex: norte, nordeste, etc..\n",
        "        self.community_term = community_term # termo usado no artigo para descrever as comunidades. ex: quilombos, quilombo, etc...\n",
        "        self.all_regions_term = all_regions_term # usado para descrever \"todas as regiões\". ex: todas as regiões da bahia\n",
        "\n",
        "    def get_community_description(self) -> str:\n",
        "        \"\"\"Get community description for CSV.\"\"\"\n",
        "        if self.internal_region == \"todas as regiões\": # verifica se internal region é igual a string \"todas as regiões\". Se for, continua pra dentro do if\n",
        "            return f\"COMUNIDADES DE TODAS AS REGIÕES DE {self.state_name.upper()}\" # retorna \"COMUNIDADES DE TODAS AS REGIÕES DE Nome-do-Estado\"\n",
        "        return f\"COMUNIDADES DE {self.internal_region.upper()} DE {self.state_name.upper()}\" # se if não foi satisfeito, vem pra cá. onde fala o nome da região interna\n",
        "                                                                                             # e o nome do estado\n",
        "\n",
        "    def get_report_text(self, article: Article) -> str:\n",
        "        \"\"\"Get report text for output.\"\"\"\n",
        "        if self.internal_region == \"todas as regiões\": # verifica se internal region é igual a \"todas as regiões\". Se sim, entra no if\n",
        "            return (f\"Quilombos de todas as regiões de {self.state_name.title()}, \"\n",
        "                   f\"na região {self.country_region.title()},\\n\"\n",
        "                   f\"são mencionados no artigo de ID {article.id + 2} da tabela,\\n\"\n",
        "                   f\"estudados pela instituição {article.institution.title()}.\\n\") # retorna esse texto falando estado, região, id do artigo e a instituição que estudou\n",
        "        return (f\"Quilombos do {self.internal_region} de {self.state_name.title()}, \"\n",
        "               f\"na região {self.country_region.title()},\\n\"\n",
        "               f\"são mencionados no artigo de ID {article.id + 2} da tabela,\\n\"\n",
        "               f\"estudados pela instituição {article.institution.title()}.\\n\") # Retorna esse texto falando região interna, estado,  região, id do artigo e\n",
        "                                                                               # a instituição que estudou\n",
        "\n",
        "# =============================================================================\n",
        "# CORE MATCHING LOGIC\n",
        "# =============================================================================\n",
        "\n",
        "# principal classe do programa, onde serão carregados os artigos e comunidades e ocorrerá o entrelaçamento dos dados. Encontrar comunidades em artigos\n",
        "class QuilombolaAnalyzer:\n",
        "    \"\"\"Main analyzer class with all matching logic consolidated.\"\"\"\n",
        "\n",
        "    # Constants\n",
        "    # aqui ficam os nomes que são ambiguos para não confundir os algoritmos. ex: a palavra \"corte\" pode ser uma comunidade (q existe realmente) ou no sentido de cortar\n",
        "    AMBIGUOUS_NAMES = {\n",
        "        \"frança\", \"ovo\", \"um\", \"kalunga\", \"base\", \"peixes\", \"forte\",\n",
        "        \"alto\", \"piauí\", \"floresta\", \"américa\", \"brasileira\",\n",
        "        \"araçá\", \"jatobá\", \"jurema\", \"aroeira\", \"pilões\", \"piloes\",\n",
        "        \"matá\", \"mocambo\", \"solidão\", \"crioulo\", \"corte\", \"palmeiras\",\n",
        "        \"porções\", \"porção\", \"batalha\", \"barreiras\",\n",
        "        \"são paulo\", \"Pedra do Sal\", \"chapada\", \"capivari\",\n",
        "        \"Jequitibá\"\n",
        "    }\n",
        "    # para resolver os nomes ambiduos, antes deles devem ter algum dos seguintes termos, para ter uma \"desambiguação\"\n",
        "    DISAMBIGUATORS = {\n",
        "        \"comunidade\", \"comunidade quilombola\", \"comunidade remanescente\",\n",
        "        \"quilombo\", \"quilombos\", \"comunidade kilombola\", \"kilombo\", \"crq\", \"crqs\",\n",
        "        \"território quilombola\", \"território kilombola\", \"povoado\"\n",
        "    }\n",
        "\n",
        "    EXCLUDED_TERMS = {\"quilombo\", \"quilombolas\", \"quilombo \", \"um\", \"alto\", \"são francisco\"} # termos excluidos\n",
        "    PARA_STATE = \"pará\" # Uma exceção para deixar pará com acento, antes seria \"para\" poderia ser \"pará\" ou \"para algo\". Agora tem acento.\n",
        "\n",
        "    # Regional matcher constants\n",
        "    COMMUNITY_TERMS = {\n",
        "        \"quilombos\", \"comunidades\", \"quilombolas\", \"territórios\", \"povoados\",\n",
        "        \"assentamentos\", \"kilombos\", \"kilombolas\"\n",
        "    }\n",
        "\n",
        "    PREPOSITIONS = {\"de\", \"da\", \"do\", \"em\", \"na\", \"no\", \"dos\", \"das\"}\n",
        "\n",
        "    INTERNAL_REGIONS = {\n",
        "        \"norte\", \"sul\", \"leste\", \"oeste\", \"nordeste\", \"sudeste\", \"sudoeste\",\n",
        "        \"noroeste\", \"centro\", \"interior\", \"sertão\", \"litoral\", \"serra\",\n",
        "        \"vale\", \"região\", \"regiões\", \"recôncavo\"\n",
        "    }\n",
        "\n",
        "    ALL_REGIONS_TERMS = {\n",
        "        \"todas as regiões\", \"toda a região\", \"todas regiões\", \"toda região\",\n",
        "        \"diversas regiões\", \"várias regiões\", \"múltiplas regiões\"\n",
        "    }\n",
        "\n",
        "    STATE_NAMES = {\n",
        "        \"acre\", \"alagoas\", \"amazonas\", \"amapá\", \"bahia\", \"ceará\",\n",
        "        \"distrito federal\", \"espírito santo\", \"goiás\", \"maranhão\",\n",
        "        \"minas gerais\", \"mato grosso do sul\", \"mato grosso\", \"pará\",\n",
        "        \"paraíba\", \"pernambuco\", \"piauí\", \"paraná\", \"rio de janeiro\",\n",
        "        \"rio grande do norte\", \"rondônia\", \"roraima\", \"rio grande do sul\",\n",
        "        \"santa catarina\", \"sergipe\", \"são paulo\", \"tocantins\"\n",
        "    }\n",
        "\n",
        "    GENTILIC_TO_STATE = {\n",
        "        \"acreano\": (\"acre\", \"ac\"), \"acreana\": (\"acre\", \"ac\"), \"acriano\": (\"acre\", \"ac\"),\n",
        "        \"alagoano\": (\"alagoas\", \"al\"), \"alagoana\": (\"alagoas\", \"al\"),\n",
        "        \"amazonense\": (\"amazonas\", \"am\"),\n",
        "        \"amapaense\": (\"amapá\", \"ap\"),\n",
        "        \"baiano\": (\"bahia\", \"ba\"), \"baiana\": (\"bahia\", \"ba\"), \"baiense\": (\"bahia\", \"ba\"),\n",
        "        \"cearense\": (\"ceará\", \"ce\"),\n",
        "        \"brasiliense\": (\"distrito federal\", \"df\"),\n",
        "        \"capixaba\": (\"espírito santo\", \"es\"), \"espírito santense\": (\"espírito santo\", \"es\"),\n",
        "        \"goiano\": (\"goiás\", \"go\"), \"goiana\": (\"goiás\", \"go\"),\n",
        "        \"maranhense\": (\"maranhão\", \"ma\"),\n",
        "        \"mineiro\": (\"minas gerais\", \"mg\"), \"mineira\": (\"minas gerais\", \"mg\"),\n",
        "        \"sul-mato-grossense\": (\"mato grosso do sul\", \"ms\"),\n",
        "        \"mato-grossense\": (\"mato grosso\", \"mt\"),\n",
        "        \"paraense\": (\"pará\", \"pa\"), \"parauara\": (\"pará\", \"pa\"), \"paraoara\": (\"pará\", \"pa\"),\n",
        "        \"paraibano\": (\"paraíba\", \"pb\"), \"paraibana\": (\"paraíba\", \"pb\"),\n",
        "        \"pernambucano\": (\"pernambuco\", \"pe\"), \"pernambucana\": (\"pernambuco\", \"pe\"),\n",
        "        \"piauiense\": (\"piauí\", \"pi\"),\n",
        "        \"paranaense\": (\"paraná\", \"pr\"),\n",
        "        \"fluminense\": (\"rio de janeiro\", \"rj\"),\n",
        "        \"potiguar\": (\"rio grande do norte\", \"rn\"), \"norte-rio-grandense\": (\"rio grande do norte\", \"rn\"), \"rio-grandense-do-norte\": (\"rio grande do norte\", \"rn\"),\n",
        "        \"rondoniense\": (\"rondônia\", \"ro\"), \"rondoniano\": (\"rondônia\", \"ro\"),\n",
        "        \"roraimense\": (\"roraima\", \"rr\"),\n",
        "        \"gaúcho\": (\"rio grande do sul\", \"rs\"), \"gaúcha\": (\"rio grande do sul\", \"rs\"), \"sul-rio-grandense\": (\"rio grande do sul\", \"rs\"), \"rio-grandense-do-sul\": (\"rio grande do sul\", \"rs\"),\n",
        "        \"catarinense\": (\"santa catarina\", \"sc\"), \"barriga-verde\": (\"santa catarina\", \"sc\"),\n",
        "        \"sergipano\": (\"sergipe\", \"se\"), \"sergipana\": (\"sergipe\", \"se\"),\n",
        "        \"paulista\": (\"são paulo\", \"sp\"),\n",
        "        \"tocantinense\": (\"tocantins\", \"to\")\n",
        "    }\n",
        "\n",
        "    STATE_TO_UF = {\n",
        "        \"acre\": \"ac\", \"alagoas\": \"al\", \"amazonas\": \"am\", \"amapá\": \"ap\",\n",
        "        \"bahia\": \"ba\", \"ceará\": \"ce\", \"distrito federal\": \"df\", \"espírito santo\": \"es\",\n",
        "        \"goiás\": \"go\", \"maranhão\": \"ma\", \"minas gerais\": \"mg\", \"mato grosso do sul\": \"ms\",\n",
        "        \"mato grosso\": \"mt\", \"pará\": \"pa\", \"paraíba\": \"pb\", \"pernambuco\": \"pe\",\n",
        "        \"piauí\": \"pi\", \"paraná\": \"pr\", \"rio de janeiro\": \"rj\", \"rio grande do norte\": \"rn\",\n",
        "        \"rondônia\": \"ro\", \"roraima\": \"rr\", \"rio grande do sul\": \"rs\", \"santa catarina\": \"sc\",\n",
        "        \"sergipe\": \"se\", \"são paulo\": \"sp\", \"tocantins\": \"to\"\n",
        "    }\n",
        "\n",
        "    UF_TO_REGION = {\n",
        "        \"ac\": \"norte\", \"al\": \"nordeste\", \"am\": \"norte\", \"ap\": \"norte\",\n",
        "        \"ba\": \"nordeste\", \"ce\": \"nordeste\", \"df\": \"centro-oeste\", \"es\": \"sudeste\",\n",
        "        \"go\": \"centro-oeste\", \"ma\": \"nordeste\", \"mg\": \"sudeste\", \"ms\": \"centro-oeste\",\n",
        "        \"mt\": \"centro-oeste\", \"pa\": \"norte\", \"pb\": \"nordeste\", \"pe\": \"nordeste\",\n",
        "        \"pi\": \"nordeste\", \"pr\": \"sul\", \"rj\": \"sudeste\", \"rn\": \"nordeste\",\n",
        "        \"ro\": \"norte\", \"rr\": \"norte\", \"rs\": \"sul\", \"sc\": \"sul\",\n",
        "        \"se\": \"nordeste\", \"sp\": \"sudeste\", \"to\": \"norte\"\n",
        "    }\n",
        "\n",
        "    # construtor para carregar tabelas de comunidade, artigo e ter os outputs.\n",
        "    def __init__(self, communities_file: str, articles_file: str,\n",
        "                 output_txt_file: str = \"resultados.txt\",\n",
        "                 output_csv_file: str = \"resultados_detalhados.csv\",\n",
        "                 articles_copy_file: str = \"artigos_final.csv\"):\n",
        "\n",
        "\n",
        "        self.communities_file = communities_file # caminho para a tabela de comunidades quilombolas -> comunidades_quilombolas.csv\n",
        "        self.articles_file = articles_file #  caminho para a tabela de artigos -> artigos_atual.csv\n",
        "        self.output_txt_file = output_txt_file # caminho para a saida dos arquivos em texto -> resultados.txt\n",
        "        self.output_csv_file = output_csv_file # caminho para a saida csv -> resultados_detalhados.csv\n",
        "        self.articles_copy_file = articles_copy_file # Caminho para \"saida final\" -> artigos_final.csv\n",
        "\n",
        "        # Load data\n",
        "        self.communities = self._load_communities() # carrega a tabela de comunidades\n",
        "        self.articles = self._load_articles() # carrega a tabela de artigos\n",
        "        self.communities_df = load_communities_csv(communities_file) # Carrega os arquivos como DataDrame com dados brutos de comunidades (id, região, etc..)\n",
        "        self.articles_df = load_articles_csv(articles_file) # Carrega os arquivos como DataDrame com dados brutos de artigos (title, abstract, etc..)\n",
        "\n",
        "        # Results tracking\n",
        "        self.article_community_matches = []  # (article_id, community_id, matched_community_name)\n",
        "        self.regional_matches = []  # (article_id, RegionalMatch)\n",
        "        self.csv_results = []  # (community, article) pairs for CSV export\n",
        "\n",
        "        # Compile regional patterns\n",
        "        self._compile_regional_patterns()\n",
        "\n",
        "    def _load_communities(self) -> List[Community]:\n",
        "        \"\"\"Load and process communities data.\"\"\"\n",
        "\n",
        "        df = load_communities_csv(self.communities_file) # df recebe O dataFrame de comunidades quilombolas (id, região, etc..)\n",
        "        communities = [] # cria uma lista (vazia) para ficar as informações da comunidade\n",
        "\n",
        "        df['uf_clean'] = df.iloc[:, 2].apply(lambda x: x.strip().lower()) # cria a coluna \"uf_clean\", pega os dados da coluna 2 (UF) e rmv espaços extras e deixa em minusculo\n",
        "        df['state'] = df['uf_clean'].apply(get_state_name) # cria a col \"state\", pega os dados de \"uf_clean\" e deixa com o nome do estado. ex: uf_clea: \"ba\" -> state: bahia\n",
        "\n",
        "        for idx, row in df.iterrows(): # loop. idx -> indice da linha. row: pegas as informações do objeto daquela linha. ex:\n",
        "                                       # idx    Nome      Idade\n",
        "                                       #  0    Pessoa      20\n",
        "                                       # for idx, row df.interrows -> sai\n",
        "                                                                      # Nome Pessoa\n",
        "                                                                      # Idade 20\n",
        "            names = split_communities(clean_text(row.iloc[5])) # names recebe as comunidades divididadas\n",
        "                                                               # ex: Se tem \"Quilombo Kalunga, Quilombo Vão\", names = [\"Quilombo Kalunga\", \"Quilombo Vão\"].\n",
        "            original_muni_str = row.iloc[3].strip().lower() # original_muni_str recebe o municipio, porem sem espaços extras e em minusculo\n",
        "            municipalities = split_municipalities(original_muni_str) # municipalities recebe os municipios divididos\n",
        "                                                                     # ex: se tem \"Cavalcante/Teresina\", municipalities = [\"Cavalcante\", \"Teresina\"].\n",
        "\n",
        "            uf = row['uf_clean'] # uf vai receber o conteudo da coluna \"uf_clean\"\n",
        "            state = row['state'] # state vai receber o conteudo da coluna \"state\"\n",
        "            region = row.iloc[1].strip().lower() # region recebe as regiões, porem sem espaços e minusculo\n",
        "\n",
        "            # for em cadeia\n",
        "            for name in names: # faz um loop de name em names\n",
        "                for municipality in municipalities: # faz um loop de municipality em municipalities\n",
        "                    community = Community(\n",
        "                        id=idx, name=name, municipality=municipality,\n",
        "                        uf=uf, state=state, region=region,\n",
        "                        original_municipality_str=original_muni_str\n",
        "                    ) # community instancia um objeto da classe Community\n",
        "                    communities.append(community) # adiciona \"community\" a lista communities\n",
        "\n",
        "        return communities # retorna as informações da comunidade (nome, município, estado, etc.)\n",
        "\n",
        "    def _load_articles(self) -> List[Article]:\n",
        "        \"\"\"Load and process articles data.\"\"\"\n",
        "\n",
        "        df = load_articles_csv(self.articles_file) # df recebe o DataDrame com dados brutos de artigos (title, abstract, etc..)\n",
        "\n",
        "        # Preprocess text fields\n",
        "        for col in [21, 22, 23, 28, 29, 32, 33, 34, 17]: # col itera sobre as colunas listadas\n",
        "\n",
        "            #obs: serve pra limpar o texto de todas as colunas do loop.\n",
        "            col_name = f'clean_col_{col}' # col_name vai receber \"clean_col_[Numero que ele está iterando]\"\n",
        "            df[col_name] = df.iloc[:, col].apply(clean_article_text) # texto da coluna de col_name [em relação a coluna atual do loop] é limpa\n",
        "\n",
        "        articles = [] # cria uma lista (vazia) para colocar ficar as informações dos artigos\n",
        "        for index, row in df.iterrows(): # loop. idx -> indice da linha. row: pegas as informações do objeto daquela linha. obs: tem um ex pratico mais acima\n",
        "            article = Article(\n",
        "                id=index,\n",
        "                title=row[f'clean_col_21'],\n",
        "                title_alt1=row[f'clean_col_22'],\n",
        "                title_alt2=row[f'clean_col_23'],\n",
        "                keywords=row[f'clean_col_28'],\n",
        "                keywords_alt=row[f'clean_col_29'],\n",
        "                abstract=row[f'clean_col_32'],\n",
        "                abstract_alt1=row[f'clean_col_33'],\n",
        "                abstract_alt2=row[f'clean_col_34'],\n",
        "                institution=row[f'clean_col_17']\n",
        "            )  # article instancia um objeto da classe Article\n",
        "            articles.append(article) # adiciona \"article\" a lista articles\n",
        "\n",
        "        return articles  # retorna as informações dos artigos\n",
        "\n",
        "    def _compile_regional_patterns(self):\n",
        "        \"\"\"Compile regex patterns for regional matching.\"\"\"\n",
        "        community_terms = \"|\".join(self.COMMUNITY_TERMS) # junta community_terms em uma string separada por |. ex:community_terms = \"quilombo|comunidade|mocambo\n",
        "        prepositions = \"|\".join(self.PREPOSITIONS) #Junta preposições em uma string. ex.: prepositions = \"de|do|da|das\"\n",
        "        internal_regions = \"|\".join(self.INTERNAL_REGIONS) # Junta regiões internas. ex: internal_regions = \"sertão|litoral|agreste\"\n",
        "        state_names = \"|\".join(self.STATE_NAMES) # Junta nomes de estados. ex: state_names = \"Bahia|Pernambuco|Pará\"\n",
        "        gentilics = \"|\".join(self.GENTILIC_TO_STATE.keys()) # Junta gentílicos (\"baiano\", \"pernambucano\"). ex: gentilics = \"baiano|pernambucano\"\n",
        "        all_regions_terms = \"|\".join(self.ALL_REGIONS_TERMS) # Junta termos como \"todas as regiões\".ex: all_regions_terms = \"todas as regiões|todas regiões\"\n",
        "\n",
        "        # Cria um padrão para até dois adjetivos opcionais, evitando confundir com preposições, regiões, ou estados.\n",
        "        # ex: Para \"quilombos tradicionais do sertão da Bahia\", captura \"tradicionais\" como adjetivo.\n",
        "        adjective_pattern = r'(?:\\s+(?!(?:' + prepositions + r'|' + internal_regions + r'|' + state_names + r')\\b)\\w+){0,2}'\n",
        "\n",
        "        # O codigo abaixo cria uma lista de quatro expressões regulares para capturar:\n",
        "        # Menções com região interna e nome do estado (ex: \"quilombos do sertão da Bahia\")\n",
        "        # Menções com região interna e gentílico (ex: \"quilombos do sertão baiano\")\n",
        "        # Menções com \"todas as regiões\" e nome do estado (ex: \"quilombos de todas as regiões da Bahia\")\n",
        "        # Menções com \"todas as regiões\" e gentílico (ex.: \"quilombos de todas as regiões baiano\")\n",
        "\n",
        "        # Four regional patterns\n",
        "        self.regional_patterns = [\n",
        "            re.compile(rf'\\b({community_terms}){adjective_pattern}\\s+({prepositions})\\s+({internal_regions})\\s+({prepositions})\\s+({state_names})\\b', re.IGNORECASE),\n",
        "            re.compile(rf'\\b({community_terms}){adjective_pattern}\\s+({prepositions})\\s+({internal_regions})\\s+({gentilics})\\b', re.IGNORECASE),\n",
        "            re.compile(rf'\\b({community_terms}){adjective_pattern}\\s+({prepositions})\\s+({all_regions_terms})\\s+({prepositions})\\s+({state_names})\\b', re.IGNORECASE),\n",
        "            re.compile(rf'\\b({community_terms}){adjective_pattern}\\s+({prepositions})\\s+({all_regions_terms})\\s+({gentilics})\\b', re.IGNORECASE)\n",
        "        ]\n",
        "\n",
        "    # =============================================================================\n",
        "    # HIERARCHY MANAGEMENT\n",
        "    #\n",
        "    # Esses métodos são responsáveis por identificar relações hierárquicas entre comunidades quilombolas, ou seja, determinar se uma comunidade mencionada\n",
        "    # em um artigo pode estar relacionada a outras comunidades no mesmo município ou estado, com base em seus nomes. Isso é importante porque\n",
        "    # nomes de comunidades podem ser ambíguos (ex.: \"Quilombo São José\" pode existir em vários lugares) ou hierárquicos\n",
        "    # (ex.: \"Quilombo Kalunga\" pode incluir subcomunidades como \"Kalunga Vão\").\n",
        "    # =============================================================================\n",
        "\n",
        "    def find_hierarchy_for_community(self, target_community: Community) -> List[Community]:\n",
        "        \"\"\"Find hierarchical relationships for a community.\"\"\"\n",
        "\n",
        "        # recebe a comunidade alvo e verifica e retorna uma lista de comunidades relacionadas, 1° por municipio e caso contrario, estado.\n",
        "        # ex de problema que resolve: se o artigo menciona \"São José\", quais comunidades com esse nome ou variantes (ex: São José do cabo) estão no mesmo município ou estado ?\n",
        "\n",
        "        # Step 1: Same municipality\n",
        "        # IMPORTANTE: aqui no passo 1, ele verifica não só o municipio, também o estado. Mas pra ter certeza que é o municipio do estado correto. ex: tem belem no PA e PB..\n",
        "        municipality_hierarchy = self._find_hierarchy_in_scope(\n",
        "            target_community,\n",
        "            lambda c: (c.municipality.lower() == target_community.municipality.lower() and\n",
        "                      c.uf.lower() == target_community.uf.lower())\n",
        "        ) # Faz um filtro que seleciona comunidades com o mesmo município (c.municipality) e estado (c.uf) da target_community, ignorando maiúsculas/minúsculas.\n",
        "          # em resumo, municipality_hierarchy é uma lista de comunidades relacionadas no mesmo município da comunidade alvo.\n",
        "\n",
        "        if len(municipality_hierarchy) > 1: # verifica se o tamanho de municipality_hierarchy (comunidades no municipio da comunidade alvo) for maior que 1\n",
        "            return sorted(municipality_hierarchy, key=lambda c: len(c.name)) # retorna uma lista ordenada com o tamanho do nome, do menor pro maior\n",
        "\n",
        "        # Se não houver mais de uma comunidade no mesmo município, então não entra no if acima, vem pra cá\n",
        "        # Step 2: Same state\n",
        "        state_hierarchy = self._find_hierarchy_in_scope(\n",
        "            target_community,\n",
        "            lambda c: c.uf.lower() == target_community.uf.lower()\n",
        "        ) # verifica comunidades no mesmo estado (UF) e seleciona todas as comunidades do estado da comunidade alvo.\n",
        "\n",
        "        if len(state_hierarchy) > 1:  # verifica se o tamanho de municipality_hierarchy (comunidades no estado da comunidade alvo) for maior que 1\n",
        "            return sorted(state_hierarchy, key=lambda c: len(c.name))  # retorna uma lista ordenada com o tamanho e nome\n",
        "\n",
        "        return [target_community] # Se nenhuma hierarquia for encontrada (no município e no estado), retorna uma lista contendo apenas a target_community.\n",
        "\n",
        "    def _find_hierarchy_in_scope(self, target_community: Community, scope_filter) -> List[Community]:\n",
        "        \"\"\"Find hierarchy within a specific scope.\"\"\"\n",
        "\n",
        "        # Filtra comunidades dentro de um escopo (definido por scope_filter) e retorna aquelas que tem uma relação hierárquica com a target_community.\n",
        "\n",
        "        scope_communities = [c for c in self.communities if scope_filter(c)] # scope_communities recebe \"c\" se scope_filtetr(c) for true. Logo, é uma lista de\n",
        "                                                                             # comunidades que atendem ao filtro a depender dos argumentos de scope_filter\n",
        "\n",
        "                                                                             # Scope_filter é um parametro, que quando colocado algum argumento como por exemplo:\n",
        "                                                                             # c ser \"Se scope_filter é lambda c: c.municipality.lower() == \"cavalcante\" and c.uf.lower() == \"go\", scope_communities\",\n",
        "                                                                             # ele retorna true ou false, se tem relação municipio/estado com a comunidade alvo.\n",
        "\n",
        "        hierarchical_communities = [] # lista vazia pra retornar comunidades hierarquicamente relacionadas\n",
        "\n",
        "        for community in scope_communities: # loop de community em scope_communities (comunidades filtradas que tem correlação com a comunidade alvo em estado e/ou municipio)\n",
        "            if self._has_word_boundary_relationship(target_community, community): # Verifica quais comunidades \"filtradas\" tem uma relação hierarquica com a target_community\n",
        "                hierarchical_communities.append(community) # se verdadeiro, vai adicionar a lista hierarchical_communities\n",
        "\n",
        "        return hierarchical_communities # retorna a lista de comunidades hierarquicamente relacionadas com a comunidade alvo\n",
        "\n",
        "\n",
        "    def _has_word_boundary_relationship(self, target_community: Community, candidate_community: Community) -> bool:\n",
        "        \"\"\"Check if two communities have a hierarchical relationship.\"\"\"\n",
        "\n",
        "        # Verifica se duas comunidades têm uma relação hierarquica com base em seus nomes, retornando True se forem a mesma comunidade ou\n",
        "        # se um nome está contido no outro com limites de palavra. ex: \"São José\" está em \"Quilombo São José\"\n",
        "\n",
        "        if (target_community.id == candidate_community.id and\n",
        "            target_community.name == candidate_community.name): # verifica se a comunidade candidata é a comunidade alvo pelo nome e id\n",
        "            return True # se for, vai retornar true\n",
        "\n",
        "        target_variants = self._get_normalized_variants(target_community.name) # target_variants recebe diferentes variantes do nome da comunidade\n",
        "        candidate_variants = self._get_normalized_variants(candidate_community.name) # candidate_variants recebe diferentes variantes do nome da comunidade\n",
        "\n",
        "        # for em cadeia para verificar\n",
        "        for target_variant in target_variants: # faz um loop de target_variant em target_variants\n",
        "            for candidate_variant in candidate_variants: # faz um loop de candidate_variant em candidate_variants\n",
        "                if (self._is_word_boundary_match(target_variant, candidate_variant) or\n",
        "                    self._is_word_boundary_match(candidate_variant, target_variant)): # Se alguma combinação bater, retorna True\n",
        "                    return True # retorna true\n",
        "\n",
        "        return False # Se nenhuma combinação bater, retorna False\n",
        "\n",
        "    def _get_normalized_variants(self, community_name: str) -> Set[str]:\n",
        "        \"\"\"Get normalized variants of a community name.\"\"\"\n",
        "\n",
        "        # faz um conjunto de variantes normalizadas de um nome de comunidade, com versões com e sem acentos e com os tratamentos de apostrofos.\n",
        "        variants = set() # coleção (ou lista) não ordenada que não permite elementos duplicados\n",
        "\n",
        "        cleaned_name = clean_text(community_name) # limpa o conteudo de community_name, retirando espaços duplos, tab, etc.. e deixando em minusculo\n",
        "        variants.add(cleaned_name) # O conteudo de cleaned_name (nome limpo) é adicionado a variavel variants\n",
        "\n",
        "        no_diacritics = remove_diacritics(cleaned_name) # no_diacritics recebe o conteudo limpo E sem acentos\n",
        "        variants.add(no_diacritics) # # O conteudo de no_diacritics (conteudo limpo E sem acentos) é adicionado a variavel variants\n",
        "        # obs: agora variants possui: *conteudo limpo* e *conteudo limpo E sem acentos*\n",
        "\n",
        "        # Apostrophe variants\n",
        "        apostrophe_variants = normalize_apostrophes(cleaned_name) # apostrophe_variants recebe o \"cleaned_name\", porém com diferentes variantes de aposcrofos\n",
        "        variants.update(apostrophe_variants) # adiciona as varias versões que está em apostrophe_variants a variants\n",
        "\n",
        "        apostrophe_variants_no_diacritics = normalize_apostrophes(no_diacritics) # apostrophe_variants_no_diacritics recebe o \"no_diacritics\" com diferentes variantes de aposcrofos\n",
        "        variants.update(apostrophe_variants_no_diacritics)  # adiciona as varias versões que está em apostrophe_variants_no_diacritics a variants\n",
        "\n",
        "        # obs: agora variants possui: *conteudo limpo*, *conteudo limpo E sem acentos*,\n",
        "        # *conteudo limpo com diferentes variantes de aposcrofos* e  *conteudo limpo E sem acentos com diferentes variantes de aposcrofos*\n",
        "\n",
        "        variants.discard('') # remove as strings vazias no conjunto variants\n",
        "        return variants # retorna o conjunto variantes, contendo tudo oque já vimos..\n",
        "\n",
        "    def _is_word_boundary_match(self, shorter_name: str, longer_name: str) -> bool:\n",
        "        \"\"\"Check if shorter name appears as complete words in longer name.\"\"\"\n",
        "\n",
        "\n",
        "        if shorter_name == longer_name or len(shorter_name) >= len(longer_name): # Serve pra saber se um nome A é igual ao nome B ou se o nome A é maior ou igual a B\n",
        "            return False # se alguma das condições são verdadeiras, retorna falso e para.\n",
        "\n",
        "\n",
        "        escaped_shorter = re.escape(shorter_name) # escaped_shorter recebe o txt de shorter_name tratado os simbulos especiais, para não ter problemas coma regex. ex: . -> \\.\n",
        "        pattern = r'\\b' + escaped_shorter + r'\\b' # pattern recebe a captura do texto com fronteira. pra não ter coisas como \"bon\" ser pego em \"bonito\"\n",
        "\n",
        "        return bool(re.search(pattern, longer_name, re.IGNORECASE)) # verifica se pattern está em de longer_name.\n",
        "                                                                    # exemplo: \"SÃO PEDRO\" em \"SÃO PEDRO DOS BOIS\", retorna TRUE.\n",
        "\n",
        "    # =============================================================================\n",
        "    # COMMUNITY MATCHING\n",
        "    # =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "    def find_best_match_in_hierarchy(self, hierarchy: List[Community], article: Article) -> Optional[Community]:\n",
        "        \"\"\"Find the best (longest) matching community in a hierarchy.\"\"\"\n",
        "        # Sort by name length (longest first) for priority\n",
        "        sorted_hierarchy = sorted(hierarchy, key=lambda c: len(c.name), reverse=True) # ex: \"são joão\" e \"são jão da barra\", pega são jõão da barra\n",
        "                                                                                      # fica a fila: [\"são jão da barra\", \"são joão\"]\n",
        "\n",
        "        for community in sorted_hierarchy: # faz um loop de community em sorted_hierarchy (deixa o nome mais longo como prioridade, entao o loop vai do maior nome ao menor )\n",
        "            if self._check_community_match(community, article): # verifica SE a comunidade na posição \"i\" aparecer no artigo\n",
        "                return community # se aparecer, retorna a comunidade que deu \"match\"\n",
        "\n",
        "        return None # caso contrario disso, retorna nada.\n",
        "\n",
        "\n",
        "    def find_best_matches_in_hierarchy(self, hierarchy: List[Community], article: Article) -> List[Community]:\n",
        "\n",
        "        \"\"\"Encontra as melhores correspondências em uma hierarquia, retornando TODAS as válidas em caso de empate.\"\"\"\n",
        "        sorted_hierarchy = sorted(hierarchy, key=lambda c: len(c.name), reverse=True)\n",
        "\n",
        "        potential_matches = []\n",
        "        # Encontra TODAS as comunidades na hierarquia que passam na validação.\n",
        "        for community in sorted_hierarchy:\n",
        "            if self._check_community_match(community, article):\n",
        "                potential_matches.append(community)\n",
        "\n",
        "        if not potential_matches:\n",
        "            return []\n",
        "\n",
        "        # Dentre as que passaram, pega o tamanho do nome da primeira (que é a mais longa).\n",
        "        longest_name_len = len(potential_matches[0].name)\n",
        "\n",
        "        # Filtra a lista para retornar APENAS as correspondências que têm esse tamanho máximo.\n",
        "        final_matches = [\n",
        "            match for match in potential_matches if len(match.name) == longest_name_len\n",
        "        ]\n",
        "\n",
        "        return final_matches\n",
        "    def _check_community_match(self, community: Community, article: Article) -> bool:\n",
        "        \"\"\"Check if a community matches an article.\"\"\"\n",
        "        if community.name in self.EXCLUDED_TERMS: #Verifica se o nome da comunidade está em termos excluidos (\"quilombo\", \"quilombolas\")\n",
        "            return False # se sim, retorna false\n",
        "\n",
        "        # Check community name (required)\n",
        "        if not article.has_term_diacritical_insensitive(community.name): # verifica se as varias versões do nome da comunidade \"i\" está no dicionario de palavras do artigo\n",
        "            return False # se não tiver, retorna false\n",
        "\n",
        "        # ============================ NOVA LÓGICA DE VERIFICAÇÃO ============================\n",
        "        # Após confirmar que o nome curto (\"Brejo\") está no texto, verificamos se não existe\n",
        "        # um nome hierarquicamente superior (\"Brejo dos Crioulos\") também presente no texto.\n",
        "        # Isso evita a correspondência de sub-nomes.\n",
        "\n",
        "        # Obtém variantes normalizadas do nome da comunidade atual para uma comparação robusta.\n",
        "        current_name_variants = self._get_normalized_variants(community.name)\n",
        "\n",
        "        # Itera sobre a lista mestra de todas as comunidades para encontrar correspondências mais específicas.\n",
        "        for other_community in self.communities:\n",
        "            # Otimização: Considera apenas comunidades no mesmo estado e com nomes mais longos.\n",
        "            if other_community.uf == community.uf and len(other_community.name) > len(community.name):\n",
        "\n",
        "                other_name_variants = self._get_normalized_variants(other_community.name)\n",
        "\n",
        "                # Verifica se há uma relação hierárquica entre os nomes.\n",
        "                is_hierarchical = False\n",
        "                for c_variant in current_name_variants:\n",
        "                    for o_variant in other_name_variants:\n",
        "                        if self._is_word_boundary_match(c_variant, o_variant):\n",
        "                            is_hierarchical = True\n",
        "                            break\n",
        "                    if is_hierarchical:\n",
        "                        break\n",
        "\n",
        "                # Se forem hierarquicamente relacionadas, verifica se o nome mais longo também está no artigo.\n",
        "                if is_hierarchical and article.has_term_diacritical_insensitive(other_community.name):\n",
        "                    # Se uma correspondência mais longa e específica for encontrada no texto,\n",
        "                    # a atual (mais curta) é um falso positivo e deve ser descartada.\n",
        "                    return False\n",
        "\n",
        "        # Apply matching logic based on ambiguity\n",
        "        if community.name in self.AMBIGUOUS_NAMES: # verifica se a comunidade está na lista de nome ambiguos\n",
        "            return self._check_ambiguous_match(community, article) # se tiver, vai para a checagem especifica para nomes ambiguos\n",
        "        else:\n",
        "            return self._check_regular_match(community, article) # se não, vai para a checagem especifica para nomes não ambiguos\n",
        "\n",
        "    def _check_regular_match(self, community: Community, article: Article) -> bool:\n",
        "        \"\"\"Check regular community matching.\"\"\"\n",
        "        # Check municipality first (preferred)\n",
        "        if article.has_term(community.municipality): # verifica se o municipio da comunidade está em \"has_term\"\n",
        "            return True # se sim, retorna true\n",
        "\n",
        "        # Check state as fallback\n",
        "        if community.state.lower() == self.PARA_STATE: # verifica se o estado da comunidade é o \"Pará\"\n",
        "            return article.has_term(community.state) # se for, retorna a função has_term pra saber se \"Pará\" está no texto do artigo \"de forma pura\" (acentos)\n",
        "        else:\n",
        "            return article.has_term_diacritical_insensitive(community.state) # retorna a verificação do estado da comunidade, pra ver se alguma das varias versões\n",
        "                                                                             # dela está no texto\n",
        "\n",
        "    def _check_ambiguous_match(self, community: Community, article: Article) -> bool:\n",
        "        \"\"\"Check ambiguous community matching (requires disambiguators).\"\"\"\n",
        "\n",
        "        ###  obs: quando essa função é chamada, garante que existe o nome da comunidade no artigo ###\n",
        "\n",
        "        text = article.get_full_text() # text vai recebeer o texto \"puro\" (sem tratamento) do artigo\n",
        "        mentions = 0 # menções a comunidade inicia com 0\n",
        "        has_ambiguous = False\n",
        "\n",
        "        # Find community name mentions with disambiguators\n",
        "        community_pattern = r'\\b' + re.escape(community.name) + r'\\b' # deixa o nome da comunidade tratado pra entrr no regex. ex: \".\" vira \"\\.\", para não ficar como \"comando\"\n",
        "        occurrences = [m.start() for m in re.finditer(community_pattern, text, re.IGNORECASE)] # procura o nome da comunidade tratada no texto do artigo. insensivel a maiu/minu\n",
        "                                                                                               # obs1: Se o finditer não achar correspondencia a lista fica vazia: []\n",
        "                                                                                               # obs: m.start() retorna a posição do indice\n",
        "\n",
        "        if occurrences: # se ocorrencias existir (não estiver vazio), a condição é atendida\n",
        "            for pos in occurrences:\n",
        "                text_before = text[:pos].strip() # text_before recebe o texto do inicio até \"pos\" (que é onde está o indice do nome \"i\")\n",
        "                words_before = text_before.split()[-4:] # words_before divide o texto anterior deixa as ultimas 4 palavra antes de pós\n",
        "                context = \" \".join(words_before) # junta as 4 palavras em uma só string\n",
        "\n",
        "                for disamb in self.DISAMBIGUATORS: # faz o loop de disamb em DISAMBIGUATORS (lista de palavras pra verificar se é uma comunidade, ex: quilombo, vila, etc...)\n",
        "                    if re.search(r'\\b' + re.escape(disamb) + r'\\b', context): # procura o exato nome \"i\" que está em \"disamb\" nas 4 palavras antes do nome ambiguo\n",
        "                        has_ambiguous = True\n",
        "                        mentions += 1 #  se verdadeiro (ou seja,if retornar verdadeiro que tem o nome), mentions = mentions + 1\n",
        "                        break # após a menção, tem uma parada e volta pro inicio do loop, até terminar os indices de occurrences\n",
        "\n",
        "\n",
        "        if article.has_term(community.municipality): # Check municipality mention -> verificar se o nome do municipio aparece no artigo\n",
        "            mentions += 1\n",
        "\n",
        "        elif community.state.lower() == self.PARA_STATE: # Check state mention if municipality not mentioned -> verificar se o nome \"Pará\" é o nome do estado da comunidade\n",
        "            if article.has_term(community.state): # verificar se o nome \"Pará\" aparece no artigo\n",
        "                mentions += 1\n",
        "        elif article.has_term_diacritical_insensitive(community.state): # verifica se o nome do estado aparece no artigo\n",
        "            mentions += 1\n",
        "\n",
        "        return has_ambiguous and mentions >= 2  # garantir que o nome realmente é uma comunidade quilombola, além das menções ao estado e municipio\n",
        "\n",
        "    # =============================================================================\n",
        "    # REGIONAL MATCHING\n",
        "    # =============================================================================\n",
        "\n",
        "    def find_regional_matches(self, article: Article) -> List[RegionalMatch]:\n",
        "        \"\"\"Find regional quilombo mentions in an article.\"\"\"\n",
        "        matches = [] # lista matches que está inicialmente vazia\n",
        "        text = article.get_full_text() # text recebe o texto completlo \"bruto\"\n",
        "        seen_combinations = set() # seen_combinations é um conjunto que não permite duplicatas nele\n",
        "\n",
        "        #observações para pattern 1:\n",
        "        #grupo 1: community_terms\n",
        "        #grupo 2: prepositions\n",
        "        #grupo 3: internal_regions\n",
        "        #grupo 4: prepositions\n",
        "        #grupo 5: state_names\n",
        "\n",
        "        # Pattern 1: community + prep + region + prep + state , sendo \"prep\": preposição\n",
        "        for match in self.regional_patterns[0].finditer(text): # prucura pelas correspondencia do \"padrão\" de regional_patterns[0] no texto. ex: quilombos do sertão da Bahia\"\n",
        "            community_term = match.group(1).lower() # community_term recebe o \"grupo 1\" (community_terms) capturado pela regex\n",
        "            if not community_term.endswith('s'): # verifica se community_term termina com \"s\"\n",
        "                continue # se verdadeiro, pula o restante do codigo e vai pra proxima iteração\n",
        "\n",
        "            internal_region = match.group(3).lower() # internal_region recebe o grupo 3 capturado pela regex -> nome da região interna, ex: sertão\n",
        "            state_name = match.group(5).lower() # state_name recebe o grupo 5 capturado pela regex -> nome do estado\n",
        "\n",
        "            uf = self.STATE_TO_UF.get(state_name) # uf vai receber o conteudo de state_name\n",
        "            if uf: # se uf não for vazio\n",
        "                country_region = self.UF_TO_REGION.get(uf) # country_region vai receber a sigla do estado\n",
        "                unique_key = (internal_region, state_name, uf, country_region) # unique_key vai receber as informações:\n",
        "                                                                               # região interna,  nome do estado, sigla do estado, região)\n",
        "\n",
        "                if unique_key not in seen_combinations: # se unique_key não estiver no conjunto seen_combinations, ele entra na condicional\n",
        "                    seen_combinations.add(unique_key) # Adiciona o conteudo de unique_key a seen_combinations\n",
        "                    matches.append(RegionalMatch(\n",
        "                        internal_region=internal_region,\n",
        "                        state_name=state_name,\n",
        "                        uf=uf,\n",
        "                        country_region=country_region,\n",
        "                        community_term=community_term\n",
        "                    )) # adiciona a matches o nome da região interna e o nome do estado\n",
        "\n",
        "        #observações para pattern 2:\n",
        "        #grupo 1: community_terms\n",
        "        #grupo 2: prepositions\n",
        "        #grupo 3: internal_regions\n",
        "        #grupo 4: gentilicos\n",
        "\n",
        "        # Pattern 2: community + prep + region + gentilic\n",
        "        for match in self.regional_patterns[1].finditer(text): # prucura pelas correspondencia do \"padrão\" de regional_patterns[1] no texto. ex: \"quilombos do sertão baiano\"\n",
        "            community_term = match.group(1).lower() # community_term recebe o \"grupo 1\" (community_terms) capturado pela regex\n",
        "            if not community_term.endswith('s'):  # verifica se community_term termina com \"s\"\n",
        "                continue # se verdadeiro, pula o restante do codigo e vai pra proxima iteração\n",
        "\n",
        "            internal_region = match.group(3).lower() # internal_region recebe o grupo 3 capturado pela regex -> nome da região interna\n",
        "            gentilic = match.group(4).lower() # gentilic recebe o grupo 4 capturado pela regex -> nome getilico. ex: baiano\n",
        "\n",
        "            state_info = self.GENTILIC_TO_STATE.get(gentilic) # state_info vai receber o nome e sigla do estado ao qual o gentilico se refere. ex|: baiano -> [Bahia e BA]\n",
        "            if state_info: # se state_info tiver algum conteudo nele\n",
        "                state_name, uf = state_info # state_name recebe o nome do estado que está em state_info e uf recebe a sigla do estado que está em state_info\n",
        "                country_region = self.UF_TO_REGION.get(uf) # country_region vai receber a região onde se encontra o estado\n",
        "                unique_key = (internal_region, state_name, uf, country_region) # unique_key vai receber as informações:\n",
        "                                                                               # região interna,  nome do estado, sigla do estado, região)\n",
        "\n",
        "                if unique_key not in seen_combinations: # se unique_key não estiver no conjunto seen_combinations, ele entra na condicional\n",
        "                    seen_combinations.add(unique_key) # Adiciona o conteudo de unique_key a seen_combinations\n",
        "                    matches.append(RegionalMatch(\n",
        "                        internal_region=internal_region,\n",
        "                        state_name=state_name,\n",
        "                        uf=uf,\n",
        "                        country_region=country_region,\n",
        "                        community_term=community_term\n",
        "                    )) # adiciona a matches o nome da região interna e o nome do estado\n",
        "\n",
        "\n",
        "        #observações para pattern 3:\n",
        "        #grupo 1: community_terms\n",
        "        #grupo 2: prepositions\n",
        "        #grupo 3: all_regions_terms\n",
        "        #grupo 4: prepositions\n",
        "        #grupo 5: state_names\n",
        "\n",
        "        # Pattern 3: community + prep + \"todas as regiões\" + prep + state\n",
        "        for match in self.regional_patterns[2].finditer(text):  # procura pelas correspondencia do \"padrão\" de regional_patterns[2] no texto. ex: quilombos de todas as regiões da Bahia\n",
        "            community_term = match.group(1).lower() # community_term recebe o \"grupo 1\" (community_terms) capturado pela regex\n",
        "            if not community_term.endswith('s'): # verifica se community_term termina com \"s\"\n",
        "                continue # se verdadeiro, pula o restante do codigo e vai pra proxima iteração\n",
        "\n",
        "            all_regions_term = match.group(3).lower() # all_regions_term recebe o grupo 3 capturado pela regex -> ex: todas as regiões\n",
        "            state_name = match.group(5).lower() # state_name vai receber o nome do estado\n",
        "\n",
        "            uf = self.STATE_TO_UF.get(state_name) # uf recebe a sigla do estado\n",
        "            if uf:\n",
        "                country_region = self.UF_TO_REGION.get(uf) # country_region recebe o nome da região onde se encontra o estado\n",
        "                internal_region = \"todas as regiões\" # internal_region recebe a string  \"todas as regiões\"\n",
        "                unique_key = (internal_region, state_name, uf, country_region) # unique_key vai receber as informações:\n",
        "                                                                               # região interna,  nome do estado, sigla do estado, região)\n",
        "\n",
        "                if unique_key not in seen_combinations: # se unique_key não estiver no conjunto seen_combinations, ele entra na condicional\n",
        "                    seen_combinations.add(unique_key) # Adiciona o conteudo de unique_key a seen_combination\n",
        "                    matches.append(RegionalMatch(\n",
        "                        internal_region=internal_region,\n",
        "                        state_name=state_name,\n",
        "                        uf=uf,\n",
        "                        country_region=country_region,\n",
        "                        community_term=community_term,\n",
        "                        all_regions_term=all_regions_term\n",
        "                    )) # adiciona a matches \"COMUNIDADES DE TODAS AS REGIÕES DE Nome-do-Estado\"\n",
        "\n",
        "\n",
        "        #observações para pattern 3:\n",
        "        #grupo 1: community_terms\n",
        "        #grupo 2: prepositions\n",
        "        #grupo 3: all_regions_terms\n",
        "        #grupo 4: gentilics\n",
        "\n",
        "        # Pattern 4: community + prep + \"todas as regiões\" + gentilic\n",
        "        for match in self.regional_patterns[3].finditer(text): # procura pelas correspondencia do \"padrão\" de regional_patterns[3] no texto. ex: quilombos de todas as regiões baiano\n",
        "            community_term = match.group(1).lower() # community_term recebe o \"grupo 1\" (community_terms) capturado pela regex\n",
        "            if not community_term.endswith('s'): # verifica se community_term termina com \"s\"\n",
        "                continue # se verdadeiro, pula o restante do codigo e vai pra proxima iteração\n",
        "\n",
        "            all_regions_term = match.group(3).lower() # all_regions_term recebe o grupo 3 capturado pela regex -> ex: todas as regiões\n",
        "            gentilic = match.group(4).lower()  # gentilic recebe o grupo 4 capturado pela regex -> nome getilico. ex: baiano\n",
        "\n",
        "            state_info = self.GENTILIC_TO_STATE.get(gentilic) # state_info vai receber o nome e sigla do estado ao qual o gentilico se refere. ex|: baiano -> [Bahia e BA]\n",
        "            if state_info: # se state_info tiver algum conteudo nele\n",
        "                state_name, uf = state_info # state_name recebe o nome do estado que está em state_info e uf recebe a sigla do estado que está em state_info\n",
        "                country_region = self.UF_TO_REGION.get(uf)  # country_region vai receber a região onde se encontra o estado\n",
        "                internal_region = \"todas as regiões\" # internal_region recebe a string  \"todas as regiões\"\n",
        "                unique_key = (internal_region, state_name, uf, country_region) # unique_key vai receber as informações:\n",
        "                                                                               # região interna,  nome do estado, sigla do estado, região)\n",
        "\n",
        "                if unique_key not in seen_combinations: # se unique_key não estiver no conjunto seen_combinations, ele entra na condicional\n",
        "                    seen_combinations.add(unique_key) # o conteudo de unique_key é adicionado a seen_combinations\n",
        "                    matches.append(RegionalMatch(\n",
        "                        internal_region=internal_region,\n",
        "                        state_name=state_name,\n",
        "                        uf=uf,\n",
        "                        country_region=country_region,\n",
        "                        community_term=community_term,\n",
        "                        all_regions_term=all_regions_term\n",
        "                    )) # adiciona a matches \"COMUNIDADES DE TODAS AS REGIÕES DE Nome-do-Estado\"\n",
        "\n",
        "        return matches # retorna o conteudi de matches\n",
        "\n",
        "    # =============================================================================\n",
        "    # REPORTING\n",
        "    # =============================================================================\n",
        "\n",
        "    def generate_community_report(self, community: Community, article: Article) -> str:\n",
        "        \"\"\"Generate match report for a community.\"\"\"\n",
        "        prefix = \"Nome ambíguo\" if community.name in self.AMBIGUOUS_NAMES else \"Comunidade\"\n",
        "\n",
        "        # CONDIÇÃO CORRIGIDA: A única condição para mostrar a lista completa\n",
        "        # de municípios é se a comunidade, na sua origem, pertencer a múltiplos municípios.\n",
        "        if community.original_municipality_str and \"|\" in community.original_municipality_str:\n",
        "            # Lógica para agrupar e formatar múltiplos municípios\n",
        "            all_municipalities = split_municipalities(community.original_municipality_str)\n",
        "\n",
        "            muni_parts = [f\"{m.title()} ({community.uf.upper()})\" for m in all_municipalities[:-1]]\n",
        "            muni_str = \", \".join(muni_parts)\n",
        "            muni_str += f\", e/ou {all_municipalities[-1].title()} ({community.uf.upper()})\"\n",
        "\n",
        "            return (f\"{prefix} {community.name.title()}, do município {muni_str}, \"\n",
        "                    f\"da região {community.region.upper()},\\n\"\n",
        "                    f\"é mencionada no artigo de ID {article.id + 2} da tabela,\\n\"\n",
        "                    f\"estudada pela instituição {article.institution.title()}.\\n\")\n",
        "        else:\n",
        "            # Relatório padrão para comunidades com um único município\n",
        "            return (f\"{prefix} {community.name.title()}, do município {community.municipality.title()} \"\n",
        "                    f\"({community.uf.upper()}), da região {community.region.upper()},\\n\"\n",
        "                    f\"é mencionada no artigo de ID {article.id + 2} da tabela,\\n\"\n",
        "                    f\"estudada pela instituição {article.institution.title()}.\\n\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # EXPORT FUNCTIONS\n",
        "    # =============================================================================\n",
        "\n",
        "    def export_csv(self):\n",
        "        \"\"\"Export detailed results to CSV.\"\"\"\n",
        "        headers = [\n",
        "            \"COMUNIDADE\", \"MUNICÍPIO\", \"UF\", \"REGIÃO\", \"AUTORES\",\n",
        "            \"TÍTULO DO ARTIGO (IDIOMA 1)\", \"TÍTULO DO ARTIGO (IDIOMA 2)\",\n",
        "            \"TÍTULO DO ARTIGO (IDIOMA 3)\", \"REVISTA\", \"PALAVRAS-CHAVE (IDIOMA 1)\",\n",
        "            \"PALAVRAS-CHAVE (IDIOMA 2)\", \"RESUMO (IDIOMA 1)\", \"RESUMO (IDIOMA 2)\",\n",
        "            \"RESUMO (IDIOMA 3)\", \"INSTITUIÇÃO\"\n",
        "        ]\n",
        "\n",
        "        with open(self.output_csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile, delimiter=';')\n",
        "            writer.writerow(headers)\n",
        "\n",
        "            for community, article in self.csv_results:\n",
        "                row = [\n",
        "                    community.name.title(),\n",
        "                    community.municipality.title(),\n",
        "                    community.uf.upper(),\n",
        "                    community.region.upper(),\n",
        "                    \"\",  # AUTORES\n",
        "                    article.title,\n",
        "                    article.title_alt1,\n",
        "                    article.title_alt2,\n",
        "                    \"\",  # REVISTA\n",
        "                    article.keywords,\n",
        "                    article.keywords_alt,\n",
        "                    article.abstract,\n",
        "                    article.abstract_alt1,\n",
        "                    article.abstract_alt2,\n",
        "                    article.institution.title()\n",
        "                ]\n",
        "                writer.writerow(row)\n",
        "\n",
        "        return len(self.csv_results)\n",
        "\n",
        "    def create_enhanced_articles_copy(self):\n",
        "        \"\"\"Create enhanced articles copy with community data.\"\"\"\n",
        "        copy_df = self.articles_df.copy()\n",
        "        all_rows = []\n",
        "\n",
        "        # Add rows for community matches\n",
        "        for article_id, community_id, matched_community_name in self.article_community_matches:\n",
        "            new_row = self.articles_df.iloc[article_id].copy()\n",
        "            community_row = self.communities_df.iloc[community_id]\n",
        "\n",
        "            # Copy first 17 columns from community\n",
        "            for col_idx in range(min(17, len(community_row))):\n",
        "                new_row.iloc[col_idx] = community_row.iloc[col_idx]\n",
        "\n",
        "            # Replace community name with matched name\n",
        "            new_row.iloc[5] = matched_community_name.upper()\n",
        "            all_rows.append(new_row)\n",
        "\n",
        "        # Add rows for regional matches\n",
        "        for article_id, regional_match in self.regional_matches:\n",
        "            new_row = self.articles_df.iloc[article_id].copy()\n",
        "\n",
        "            new_row.iloc[0] = \"\"  # Empty cell\n",
        "            new_row.iloc[1] = regional_match.country_region.upper()\n",
        "            new_row.iloc[2] = regional_match.uf.upper()\n",
        "            new_row.iloc[3] = \"\"  # Municipality\n",
        "            new_row.iloc[4] = \"\"  # Other field\n",
        "            new_row.iloc[5] = regional_match.get_community_description()\n",
        "\n",
        "            all_rows.append(new_row)\n",
        "\n",
        "        # Create final dataframe\n",
        "        matched_df = pd.DataFrame(all_rows, columns=copy_df.columns)\n",
        "\n",
        "        # Get unmatched articles\n",
        "        matched_article_ids = set(aid for aid, _, _ in self.article_community_matches)\n",
        "        matched_article_ids.update(aid for aid, _ in self.regional_matches)\n",
        "\n",
        "        unmatched_df = copy_df.iloc[[i for i in range(len(copy_df)) if i not in matched_article_ids]]\n",
        "\n",
        "        # Combine and save\n",
        "        final_df = pd.concat([unmatched_df, matched_df], ignore_index=True)\n",
        "        final_df.to_csv(self.articles_copy_file, sep=';', encoding='utf-8', index=False)\n",
        "\n",
        "        return len(self.article_community_matches), len(self.regional_matches), len(unmatched_df)\n",
        "\n",
        "    def add_year_column(self):\n",
        "        \"\"\"Extract year from column 13 and add to last column.\"\"\"\n",
        "        df = pd.read_csv(self.articles_copy_file, sep=';', encoding='utf-8')\n",
        "\n",
        "        last_four_chars = df.iloc[:, 13].astype(str).apply(\n",
        "            lambda x: x[-4:] if len(x) >= 4 else x\n",
        "        )\n",
        "\n",
        "        df['ANO DA PORTARIA'] = last_four_chars\n",
        "        df.to_csv(self.articles_copy_file, sep=';', encoding='utf-8', index=False)\n",
        "\n",
        "        return len(df)\n",
        "\n",
        "    # =============================================================================\n",
        "    # MAIN ANALYSIS\n",
        "    # =============================================================================\n",
        "\n",
        "    def analyze(self) -> int:\n",
        "        \"\"\"Função de análise principal com priorização geográfica e prevenção de duplicatas.\"\"\"\n",
        "        output_buffer = io.StringIO()\n",
        "        final_matches_per_article = defaultdict(list)\n",
        "\n",
        "        # Passos 1-5: Lógica da \"versão quase-final-2.0\" para encontrar os melhores candidatos\n",
        "        for article in self.articles:\n",
        "            level_2_candidates, level_1_candidates, level_0_candidates = [], [], []\n",
        "            for community in self.communities:\n",
        "                if article.has_term_diacritical_insensitive(community.name):\n",
        "                    municipality_found = article.has_term_diacritical_insensitive(community.municipality)\n",
        "                    state_found = article.has_term_diacritical_insensitive(community.state)\n",
        "                    if municipality_found and state_found: level_2_candidates.append(community)\n",
        "                    elif municipality_found: level_1_candidates.append(community)\n",
        "                    elif state_found: level_0_candidates.append(community)\n",
        "\n",
        "            chosen_candidates = []\n",
        "            if level_2_candidates: chosen_candidates = level_2_candidates\n",
        "            elif level_1_candidates: chosen_candidates = level_1_candidates\n",
        "            elif level_0_candidates: chosen_candidates = level_0_candidates\n",
        "\n",
        "            if not chosen_candidates: continue\n",
        "\n",
        "            final_valid_matches = []\n",
        "            for candidate in chosen_candidates:\n",
        "                if self._check_community_match(candidate, article):\n",
        "                    final_valid_matches.append(candidate)\n",
        "\n",
        "            unique_matches = []\n",
        "            seen_matches = set()\n",
        "            for match in final_valid_matches:\n",
        "                match_key = (match.id, match.name, match.municipality, match.uf)\n",
        "                if match_key not in seen_matches:\n",
        "                    unique_matches.append(match)\n",
        "                    seen_matches.add(match_key)\n",
        "\n",
        "            if unique_matches:\n",
        "                final_matches_per_article[article.id] = unique_matches\n",
        "\n",
        "        # PASSO 6: GERAÇÃO DE RELATÓRIOS COM LÓGICA DE CONSOLIDAÇÃO POR ID\n",
        "        matches_count = 0\n",
        "        with redirect_stdout(output_buffer):\n",
        "            print(\"=== PRIMEIRA RODADA: COMUNIDADES ESPECÍFICAS ===\\n\")\n",
        "            article_ids_with_matches = sorted(final_matches_per_article.keys())\n",
        "\n",
        "            for article_id in article_ids_with_matches:\n",
        "                article = self.articles[article_id]\n",
        "\n",
        "                # --- LÓGICA DE CONSOLIDAÇÃO ADICIONADA AQUI ---\n",
        "                # Agrupa os resultados pelo ID da linha original do CSV.\n",
        "                grouped_by_id = defaultdict(list)\n",
        "                for match in final_matches_per_article[article_id]:\n",
        "                    grouped_by_id[match.id].append(match)\n",
        "\n",
        "                # Ordena os grupos pelo nome da comunidade para uma saída consistente.\n",
        "                sorted_groups = sorted(grouped_by_id.values(), key=lambda group: group[0].name)\n",
        "\n",
        "                # Itera sobre os grupos consolidados. Cada \"grupo\" representa uma única comunidade real.\n",
        "                for group in sorted_groups:\n",
        "                    # Pega o primeiro item do grupo como representante.\n",
        "                    representative_match = group[0]\n",
        "\n",
        "                    # Gera o relatório de texto UMA VEZ por grupo, usando a função corrigida.\n",
        "                    report = self.generate_community_report(representative_match, article)\n",
        "                    print(report)\n",
        "\n",
        "                    # Cria uma representação consolidada para o arquivo CSV.\n",
        "                    all_munis_str = representative_match.original_municipality_str.replace('|', ', ').title()\n",
        "                    csv_representation = Community(\n",
        "                        id=representative_match.id, name=representative_match.name,\n",
        "                        municipality=all_munis_str,\n",
        "                        uf=representative_match.uf, state=representative_match.state, region=representative_match.region,\n",
        "                        original_municipality_str=representative_match.original_municipality_str\n",
        "                    )\n",
        "\n",
        "                    # Adiciona aos resultados para exportação UMA VEZ por grupo.\n",
        "                    self.csv_results.append((csv_representation, article))\n",
        "                    self.article_community_matches.append((article.id, representative_match.id, representative_match.name))\n",
        "                    matches_count += 1\n",
        "\n",
        "            # O resto da função para gerar o resumo e exportar os arquivos permanece o mesmo.\n",
        "            print(\"=== SEGUNDA RODADA: MENÇÕES REGIONAIS ===\\n\")\n",
        "            unique_regional_articles = set()\n",
        "            for article in self.articles:\n",
        "                if article.id not in final_matches_per_article:\n",
        "                    regional_match_list = self.find_regional_matches(article)\n",
        "                    if regional_match_list:\n",
        "                        unique_regional_articles.add(article.id)\n",
        "                        for regional_match in regional_match_list:\n",
        "                            report = regional_match.get_report_text(article)\n",
        "                            print(report)\n",
        "                            self.regional_matches.append((article.id, regional_match))\n",
        "            regional_matches_count = len(unique_regional_articles)\n",
        "\n",
        "            print(\"=== RESUMO DOS RESULTADOS ===\\n\")\n",
        "            unique_article_count = len(final_matches_per_article)\n",
        "            print(f\"Foram encontradas {matches_count} menções a comunidades quilombolas específicas em {unique_article_count} artigos únicos.\")\n",
        "            print(f\"Foram identificados {regional_matches_count} artigos adicionais que mencionam quilombos/comunidades de forma regional.\")\n",
        "            total_articles = unique_article_count + regional_matches_count\n",
        "            print(f\"Total de artigos com menções relevantes: {total_articles}\")\n",
        "\n",
        "        with open(self.output_txt_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(output_buffer.getvalue())\n",
        "        print(output_buffer.getvalue())\n",
        "        csv_records = self.export_csv()\n",
        "        print(f\"CSV com {csv_records} registros detalhados exportado para: {self.output_csv_file}\")\n",
        "        first_count, second_count, unmatched_count = self.create_enhanced_articles_copy()\n",
        "        print(f\"Nova cópia dos artigos salva em: {self.articles_copy_file}\")\n",
        "        print(f\"  - {first_count} linhas para artigos com comunidades específicas\")\n",
        "        print(f\"  - {second_count} linhas para artigos com menções regionais\")\n",
        "        print(f\"  - {unmatched_count} linhas para artigos sem comunidades\")\n",
        "        self.add_year_column()\n",
        "        print(f\"Processamento concluído. Últimos quatro caracteres da coluna 13 adicionados\\n\"\n",
        "              f\"como nova coluna 'ANO DA PORTARIA' em: {self.articles_copy_file}\")\n",
        "\n",
        "        return total_articles\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function for running the analysis.\"\"\"\n",
        "    # Mount Google Drive (specific to Google Colab)\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "        # File paths for Colab\n",
        "        communities_file = '/content/drive/My Drive/estudo_quilombos_organizado/crqs_atual.csv'\n",
        "        articles_file = '/content/drive/My Drive/estudo_quilombos_organizado/artigos_atual.csv'\n",
        "        output_txt_file = '/content/drive/My Drive/estudo_quilombos_organizado/resultados.txt'\n",
        "        output_csv_file = '/content/drive/My Drive/estudo_quilombos_organizado/resultados_detalhados.csv'\n",
        "        articles_copy_file = '/content/drive/My Drive/estudo_quilombos_organizado/artigos_final.csv'\n",
        "    except ImportError:\n",
        "        # Local file paths (fallback)\n",
        "        communities_file = 'crqs_atual.csv'\n",
        "        articles_file = 'artigos_atual.csv'\n",
        "        output_txt_file = 'resultados.txt'\n",
        "        output_csv_file = 'resultados_detalhados.csv'\n",
        "        articles_copy_file = 'artigos_final.csv'\n",
        "\n",
        "    # Run analysis\n",
        "    analyzer = QuilombolaAnalyzer(\n",
        "        communities_file=communities_file,\n",
        "        articles_file=articles_file,\n",
        "        output_txt_file=output_txt_file,\n",
        "        output_csv_file=output_csv_file,\n",
        "        articles_copy_file=articles_copy_file\n",
        "    )\n",
        "\n",
        "    total_matches = analyzer.analyze()\n",
        "\n",
        "    print(f\"\\nAnálise concluída com {total_matches} correspondências encontradas.\")\n",
        "    print(f\"Resultados salvos em:\")\n",
        "    print(f\"  - Texto: {output_txt_file}\")\n",
        "    print(f\"  - CSV detalhado: {output_csv_file}\")\n",
        "    print(f\"  - Artigos com comunidades: {articles_copy_file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Ikwf5ezBVdsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}